{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6006e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/pyprof/__init__.py:5: FutureWarning: pyprof will be removed by the end of June, 2022\n",
      "  warnings.warn(\"pyprof will be removed by the end of June, 2022\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "torch.cuda.empty_cache()\n",
    "from pretrained_models import *\n",
    "\n",
    "from experiments.exp_def import TaskDefs, Experiment\n",
    "from data_utils.log_wrapper import create_logger\n",
    "from data_utils.task_def import EncoderModelType, TaskType\n",
    "from data_utils.utils import set_environment\n",
    "from data_utils.metrics import Metric\n",
    "\n",
    "from mt_dnn.model import MTDNNModel\n",
    "from mt_dnn.batcher import (\n",
    "    SingleTaskDataset,\n",
    "    MultiTaskDataset,\n",
    "    Collater,\n",
    "    MultiTaskBatchSampler\n",
    ")\n",
    "from train_utils import (\n",
    "    dump_opt,\n",
    "    print_message,\n",
    "    save_checkpoint\n",
    ")\n",
    "from gradient_probing import prediction_gradient\n",
    "import wandb\n",
    "\n",
    "from evaluate import get_metric, build_dataset, evaluate_model_against_multiple_datasets\n",
    "\n",
    "import warnings\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc67e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_config(parser):\n",
    "    # SET THESE\n",
    "    ##############\n",
    "    parser.add_argument('--multi_gpu_on', action='store_true')\n",
    "    parser.add_argument('--devices', nargs='+')\n",
    "\n",
    "    # head probing\n",
    "    parser.add_argument('--head_probe', action='store_true')\n",
    "    parser.add_argument('--head_probe_layer', type=int)\n",
    "    parser.add_argument('--head_probe_idx', type=int)\n",
    "    parser.add_argument('--head_probe_n_classes', type=int)\n",
    "    parser.add_argument('--head_probe_sequence', action='store_true')\n",
    "\n",
    "    # model probing\n",
    "    parser.add_argument('--model_probe', action='store_true')\n",
    "    parser.add_argument('--model_probe_n_classes', type=int)\n",
    "    parser.add_argument('--model_probe_sequence', action='store_true')\n",
    "\n",
    "    # gradient probing\n",
    "    parser.add_argument('--gradient_probe', action='store_true')\n",
    "\n",
    "    # finetuning after joint modeling\n",
    "    parser.add_argument('--jm_finetune', action='store_true')\n",
    "    parser.add_argument('--jm_finetune_new', action='store_true') # if task does not exist in 1st stage finetuning\n",
    "    parser.add_argument('--jm_task_id', type=int, default=0) # if task exists from 1st stage finetuning\n",
    "    ##############\n",
    "\n",
    "    # DON\"T NEED THESE\n",
    "    ##############\n",
    "    parser.add_argument('--update_bert_opt', default=0, type=int)\n",
    "    parser.add_argument('--mem_cum_type', type=str, default='simple',\n",
    "                        help='bilinear/simple/defualt')\n",
    "    parser.add_argument('--answer_num_turn', type=int, default=5)\n",
    "    parser.add_argument('--answer_mem_drop_p', type=float, default=0.1)\n",
    "    parser.add_argument('--answer_att_hidden_size', type=int, default=128)\n",
    "    parser.add_argument('--answer_att_type', type=str, default='bilinear',\n",
    "                        help='bilinear/simple/defualt')\n",
    "    parser.add_argument('--answer_rnn_type', type=str, default='gru',\n",
    "                        help='rnn/gru/lstm')\n",
    "    parser.add_argument('--answer_sum_att_type', type=str, default='bilinear',\n",
    "                        help='bilinear/simple/defualt')\n",
    "    parser.add_argument('--answer_merge_opt', type=int, default=1)\n",
    "    parser.add_argument('--answer_mem_type', type=int, default=1)\n",
    "    parser.add_argument('--max_answer_len', type=int, default=10)\n",
    "    parser.add_argument('--answer_dropout_p', type=float, default=0.1)\n",
    "    parser.add_argument('--answer_weight_norm_on', action='store_true')\n",
    "    parser.add_argument('--dump_state_on', action='store_true')\n",
    "    parser.add_argument('--answer_opt', type=int, default=1, help='0,1')\n",
    "    parser.add_argument('--pooler_actf', type=str, default='tanh',\n",
    "                        help='tanh/relu/gelu')\n",
    "    parser.add_argument('--mtl_opt', type=int, default=0)\n",
    "    parser.add_argument('--ratio', type=float, default=0)\n",
    "    parser.add_argument('--mix_opt', type=int, default=0)\n",
    "    parser.add_argument('--max_seq_len', type=int, default=512)\n",
    "    parser.add_argument('--init_ratio', type=float, default=1)\n",
    "    parser.add_argument('--encoder_type', type=int, default=EncoderModelType.BERT)\n",
    "    parser.add_argument('--num_hidden_layers', type=int, default=-1)\n",
    "\n",
    "    # BERT pre-training\n",
    "    parser.add_argument('--bert_model_type', type=str, default='bert-base-cased')\n",
    "    parser.add_argument('--init_checkpoint', type=str, default='bert-base-cased')\n",
    "    parser.add_argument('--do_lower_case', action='store_true')\n",
    "    parser.add_argument('--masked_lm_prob', type=float, default=0.15)\n",
    "    parser.add_argument('--short_seq_prob', type=float, default=0.2)\n",
    "    parser.add_argument('--max_predictions_per_seq', type=int, default=128)\n",
    "\n",
    "    # bin samples\n",
    "    parser.add_argument('--bin_on', action='store_true')\n",
    "    parser.add_argument('--bin_size', type=int, default=64)\n",
    "    parser.add_argument('--bin_grow_ratio', type=int, default=0.5)\n",
    "\n",
    "    # dist training\n",
    "    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n",
    "    parser.add_argument(\"--world_size\", type=int, default=1, help=\"For distributed training: world size\")\n",
    "    parser.add_argument(\"--master_addr\", type=str, default=\"localhost\")\n",
    "    parser.add_argument(\"--master_port\", type=str, default=\"6600\")\n",
    "    parser.add_argument(\"--backend\", type=str, default=\"nccl\")\n",
    "    ##############\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "def data_config(parser):\n",
    "    # SET THESE\n",
    "    ############\n",
    "    parser.add_argument('--exp_name', default='', help='experiment name')\n",
    "    parser.add_argument('--dataset_name', default='', help='dataset name')\n",
    "    parser.add_argument('--wandb', action='store_true')\n",
    "    ############\n",
    "\n",
    "    # DON'T NEED THESE\n",
    "    ############\n",
    "    parser.add_argument('--log_file', default='mt-dnn.log', help='path for log file.')\n",
    "    parser.add_argument('--data_sort_on', action='store_true')\n",
    "    parser.add_argument('--mkd-opt', type=int, default=0, \n",
    "                        help=\">0 to turn on knowledge distillation, requires 'softlabel' column in input data\")\n",
    "    parser.add_argument('--do_padding', action='store_true')\n",
    "    ############\n",
    "    return parser\n",
    "\n",
    "\n",
    "def train_config(parser):\n",
    "    # SET THESE\n",
    "    ############\n",
    "    parser.add_argument('--epochs', type=int, default=6)\n",
    "    parser.add_argument('--batch_size', type=int, default=8)\n",
    "\n",
    "    # loading\n",
    "    parser.add_argument(\"--model_ckpt\", default='', type=str)\n",
    "    parser.add_argument(\"--resume\", action='store_true')\n",
    "    parser.add_argument('--huggingface_ckpt', action='store_true')\n",
    "\n",
    "    # metrics\n",
    "    parser.add_argument('--metric_of_choice', default='F1', type=str)\n",
    "    ############\n",
    "\n",
    "    # DON'T NEED THESE\n",
    "    ############\n",
    "    parser.add_argument('--cuda', type=bool, default=torch.cuda.is_available(),\n",
    "                        help='whether to use GPU acceleration.')\n",
    "    parser.add_argument('--log_per_updates', type=int, default=100)\n",
    "    parser.add_argument('--save_per_updates', type=int, default=10000)\n",
    "    parser.add_argument('--save_per_updates_on', action='store_true')\n",
    "    parser.add_argument('--optimizer', default='adamax',\n",
    "                        help='supported optimizer: adamax, sgd, adadelta, adam')\n",
    "    parser.add_argument('--grad_clipping', type=float, default=0)\n",
    "    parser.add_argument('--global_grad_clipping', type=float, default=1.0)\n",
    "    parser.add_argument('--weight_decay', type=float, default=0)\n",
    "    parser.add_argument('--learning_rate', type=float, default=5e-5)\n",
    "    parser.add_argument('--momentum', type=float, default=0)\n",
    "    parser.add_argument('--warmup', type=float, default=0.1)\n",
    "    parser.add_argument('--warmup_schedule', type=str, default='warmup_linear')\n",
    "    parser.add_argument('--adam_eps', type=float, default=1e-6)\n",
    "\n",
    "    parser.add_argument('--vb_dropout', action='store_false')\n",
    "    parser.add_argument('--dropout_p', type=float, default=0.1)\n",
    "    parser.add_argument('--dropout_w', type=float, default=0.000)\n",
    "    parser.add_argument('--bert_dropout_p', type=float, default=0.1)\n",
    "\n",
    "    # scheduler\n",
    "    parser.add_argument('--have_lr_scheduler', dest='have_lr_scheduler', action='store_false')\n",
    "    parser.add_argument('--multi_step_lr', type=str, default='10,20,30')\n",
    "    parser.add_argument('--lr_gamma', type=float, default=0.5)\n",
    "    parser.add_argument('--scheduler_type', type=str, default='ms', help='ms/rop/exp')\n",
    "    parser.add_argument('--output_dir', default='checkpoint')\n",
    "    parser.add_argument('--seed', type=int, default=2018,\n",
    "                        help='random seed for data shuffling, embedding init, etc.')\n",
    "    parser.add_argument('--grad_accumulation_step', type=int, default=1)\n",
    "\n",
    "    #fp 16\n",
    "    parser.add_argument('--fp16', action='store_true',\n",
    "                        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\")\n",
    "    parser.add_argument('--fp16_opt_level', type=str, default='O1',\n",
    "                        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
    "                             \"See details at https://nvidia.github.io/apex/amp.html\")\n",
    "\n",
    "    # adv training\n",
    "    parser.add_argument('--adv_train', action='store_true')\n",
    "\n",
    "    # the current release only includes smart perturbation\n",
    "    parser.add_argument('--adv_opt', default=0, type=int)\n",
    "    parser.add_argument('--adv_norm_level', default=0, type=int)\n",
    "    parser.add_argument('--adv_p_norm', default='inf', type=str)\n",
    "    parser.add_argument('--adv_alpha', default=1, type=float)\n",
    "    parser.add_argument('--adv_k', default=1, type=int)\n",
    "    parser.add_argument('--adv_step_size', default=1e-5, type=float)\n",
    "    parser.add_argument('--adv_noise_var', default=1e-5, type=float)\n",
    "    parser.add_argument('--adv_epsilon', default=1e-6, type=float)\n",
    "    parser.add_argument('--encode_mode', action='store_true', help=\"only encode test data\")\n",
    "    parser.add_argument('--debug', action='store_true', help=\"print debug info\")\n",
    "\n",
    "    # transformer cache\n",
    "    parser.add_argument(\"--transformer_cache\", default='.cache', type=str)\n",
    "    ############\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7a5efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n                              '--head_probe', '--head_probe_layer', '11', '--head_probe_idx', '0',\\n                              '--head_probe_n_classes', '13',\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse args\n",
    "parser = argparse.ArgumentParser()\n",
    "parser = data_config(parser)\n",
    "parser = model_config(parser)\n",
    "parser = train_config(parser)\n",
    "\n",
    "args = parser.parse_args(args=['--devices', '0',\n",
    "                              '--exp_name', 'COARSE_cross_dummy',\n",
    "                              '--dataset_name', 'COARSE/en',\n",
    "                              #'--wandb',\n",
    "                               '--epochs', '5', '--batch_size', '16', '--learning_rate', '5e-5', '--grad_accumulation_step', '4', \n",
    "                               '--bert_model_type', 'bert-base-cased', \n",
    "                               '--fp16', '--metric_of_choice', 'MCC',\n",
    "                               #'--resume', '--huggingface_ckpt', '--model_ckpt', '/home/aadil/mt-dnn/mt_dnn_models/bert_model_base_cased.pt'\n",
    "                               '--resume', '--model_ckpt', 'checkpoint/COARSE_cross/model_4_125.pt'\n",
    "                              ])\n",
    "'''\n",
    "args = parser.parse_args(args=['--devices', '0',\n",
    "                              '--model_probe', '--model_probe_n_classes', '10', '--model_probe_sequence',\n",
    "                              '--exp_name', 'COARSE_NER',\n",
    "                              '--dataset_name', 'GOEMOTIONS/en',\n",
    "                              '--wandb',\n",
    "                              '--epochs', '2', '--batch_size', '64', '--learning_rate', '5e-3',\n",
    "                              '--bert_model_type', 'bert-base-cased', \n",
    "                              '--model_ckpt', 'checkpoint/COARSE_cross/model_4_125.pt',\n",
    "                              '--metric_of_choice', 'SeqEvalList',\n",
    "                              '--fp16',\n",
    "                              ])\n",
    "'''\n",
    "'''\n",
    "                              '--head_probe', '--head_probe_layer', '11', '--head_probe_idx', '0',\n",
    "                              '--head_probe_n_classes', '13',\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05bbef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some stuff in data can be automated\n",
    "dataset_name = args.dataset_name\n",
    "args.data_dir = f'experiments/{dataset_name}/{args.bert_model_type}'\n",
    "args.task_def = f'experiments/{dataset_name}/task_def.yaml'\n",
    "if \"/\" in dataset_name:\n",
    "    args.train_datasets = dataset_name.split(\"/\")[0].lower()\n",
    "else:\n",
    "    args.train_datasets = dataset_name.lower()\n",
    "\n",
    "# set task name, root data dir, and output dir.\n",
    "output_dir = args.output_dir\n",
    "data_dir = args.data_dir\n",
    "\n",
    "# multiple datasets are split by '_'\n",
    "args.train_datasets = args.train_datasets.split('_')\n",
    "\n",
    "# seed everything.\n",
    "set_environment(args.seed, args.cuda)\n",
    "\n",
    "# stores task: param_args for each TaskDef param\n",
    "task_defs = TaskDefs(args.task_def)\n",
    "encoder_type = args.encoder_type\n",
    "\n",
    "exp_name = args.exp_name\n",
    "\n",
    "# make log dir and set logger.\n",
    "log_path = f'logs/{exp_name}/{args.log_file}'\n",
    "Path(log_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "logger = create_logger(__name__, to_disk=True, log_file=log_path)\n",
    "\n",
    "# make output dir and set to absolute path.\n",
    "if not args.head_probe:\n",
    "    output_dir = Path(output_dir).joinpath(exp_name)\n",
    "\n",
    "output_dir = Path(os.path.abspath(output_dir))\n",
    "output_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e73f42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/13/2022 08:05:50 Launching MT-DNN training.\n"
     ]
    }
   ],
   "source": [
    "print_message(logger, 'Launching MT-DNN training.')\n",
    "opt = vars(args)\n",
    "args.devices = [int(g) for g in args.devices]\n",
    "\n",
    "tasks = {}\n",
    "task_def_list = []\n",
    "train_data_lists = []\n",
    "train_datasets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41b6a386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/13/2022 08:05:52 Loading experiments/COARSE/en/bert-base-cased/coarse_train.json as task 0\n",
      "Loaded 1600 samples out of 1600\n"
     ]
    }
   ],
   "source": [
    "# python prepro_std.py --model bert-base-multilingual-cased --dataset GOEMOTIONS/en --task_def experiments/GOEMOTIONS/en/task_def.yaml\n",
    "# create training dataset.\n",
    "for dataset in args.train_datasets:\n",
    "    prefix = dataset.split('_')[0]\n",
    "    if prefix not in tasks:\n",
    "        task_id = len(tasks)\n",
    "        tasks[prefix] = task_id\n",
    "\n",
    "        task_def = task_defs.get_task_def(prefix)\n",
    "        task_def_list.append(task_def)\n",
    "\n",
    "        train_path = os.path.join(data_dir, '{}_train.json'.format(dataset))\n",
    "        print_message(logger, 'Loading {} as task {}'.format(train_path, task_id))\n",
    "        \n",
    "        train_data_set = SingleTaskDataset(\n",
    "            path=train_path,\n",
    "            is_train=True,\n",
    "            maxlen=args.max_seq_len,\n",
    "            task_id=task_id,\n",
    "            task_def=task_def,\n",
    "            printable=True)\n",
    "\n",
    "        train_datasets.append(train_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb96df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_collater = Collater(\n",
    "    dropout_w=args.dropout_w,\n",
    "    encoder_type=encoder_type,\n",
    "    soft_label=False,\n",
    "    max_seq_len=args.max_seq_len,\n",
    "    do_padding=args.do_padding)\n",
    "\n",
    "multi_task_train_dataset = MultiTaskDataset(train_datasets)\n",
    "multi_task_batch_sampler = MultiTaskBatchSampler(\n",
    "                            train_datasets,\n",
    "                            args.batch_size,\n",
    "                            args.mix_opt,\n",
    "                            args.ratio,\n",
    "                            bin_on=args.bin_on,\n",
    "                            bin_size=args.bin_size,\n",
    "                            bin_grow_ratio=args.bin_grow_ratio)\n",
    "\n",
    "multi_task_train_dataloader = DataLoader(\n",
    "    multi_task_train_dataset,\n",
    "    batch_sampler=multi_task_batch_sampler,\n",
    "    collate_fn=train_collater.collate_fn,\n",
    "    pin_memory=len(args.devices)>0)\n",
    "\n",
    "train_data_lists.append(multi_task_train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "663563a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/13/2022 07:51:40 ############# Gradient Accumulation Info #############\n",
      "06/13/2022 07:51:40 number of step: 500\n",
      "06/13/2022 07:51:40 number of grad grad_accumulation step: 4\n",
      "06/13/2022 07:51:40 adjusted number of step: 125\n",
      "06/13/2022 07:51:40 #######################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# div number of grad accumulation. \n",
    "n_batch_per_epoch = len(multi_task_train_dataloader) // args.grad_accumulation_step\n",
    "num_all_batches = args.epochs * n_batch_per_epoch\n",
    "print_message(logger, '############# Gradient Accumulation Info #############')\n",
    "print_message(logger, 'number of step: {}'.format(args.epochs * len(multi_task_train_dataloader)))\n",
    "print_message(logger, 'number of grad grad_accumulation step: {}'.format(args.grad_accumulation_step))\n",
    "print_message(logger, 'adjusted number of step: {}'.format(num_all_batches))\n",
    "print_message(logger, '#######################################\\n')\n",
    "\n",
    "if opt['encoder_type'] not in EncoderModelType._value2member_map_:\n",
    "    raise ValueError(\"encoder_type is out of pre-defined types\")\n",
    "\n",
    "literal_encoder_type = EncoderModelType(opt['encoder_type']).name.lower()\n",
    "config_class, _, _ = MODEL_CLASSES[literal_encoder_type]\n",
    "config = config_class.from_pretrained(args.bert_model_type).to_dict()\n",
    "\n",
    "config['attention_probs_dropout_prob'] = args.bert_dropout_p\n",
    "config['hidden_dropout_prob'] = args.bert_dropout_p\n",
    "config['multi_gpu_on'] = opt[\"multi_gpu_on\"]\n",
    "\n",
    "if args.num_hidden_layers > 0:\n",
    "    config['num_hidden_layers'] = args.num_hidden_layers\n",
    "\n",
    "opt['task_def_list'] = task_def_list\n",
    "opt['head_probe'] = args.head_probe\n",
    "opt.update(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cc47744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/13/2022 07:51:40 loading model from checkpoint/COARSE_cross/model_4_125.pt\n"
     ]
    }
   ],
   "source": [
    "# if resuming, load state dict, and get init epoch and step.\n",
    "if args.resume:\n",
    "    assert args.model_ckpt != '' and Path(args.model_ckpt).is_file(), args.model_ckpt\n",
    "    print_message(logger, f'loading model from {args.model_ckpt}')           \n",
    "    state_dict = torch.load(args.model_ckpt, map_location=f'cuda:{args.devices[0]}')\n",
    "\n",
    "    if args.jm_finetune:\n",
    "        if args.jm_finetune_new:\n",
    "            i = 0\n",
    "            while f'scoring_list.{i}.weight' in state_dict['state']:\n",
    "                del state_dict['state'][f'scoring_list.{i}.weight']\n",
    "                del state_dict['state'][f'scoring_list.{i}.bias']\n",
    "                i += 1\n",
    "        else:\n",
    "            i = 0\n",
    "            while f'scoring_list.{i}.weight' in state_dict['state']:\n",
    "                if i != args.jm_task_id:\n",
    "                    del state_dict['state'][f'scoring_list.{i}.weight']\n",
    "                    del state_dict['state'][f'scoring_list.{i}.bias']\n",
    "                i += 1\n",
    "\n",
    "            if args.jm_task_id != 0:\n",
    "                for param in ['weight', 'bias']:\n",
    "                    state_dict['state'][f'scoring_list.0.{param}'] = state_dict['state'][f'scoring_list.{args.jm_task_id}.{param}']\n",
    "                    del state_dict['state'][f'scoring_list.{args.jm_task_id}.{param}']\n",
    "\n",
    "    if not args.huggingface_ckpt:\n",
    "        split_model_name = args.model_ckpt.split(\"/\")[-1].split(\"_\")\n",
    "        if len(split_model_name) > 2:\n",
    "            init_epoch_idx = int(split_model_name[1]) + 1\n",
    "            init_global_step = int(split_model_name[2].split(\".\")[0]) + 1\n",
    "        else:\n",
    "            init_epoch_idx = int(split_model_name[1].split(\".\")[0]) + 1\n",
    "            init_global_step = 0\n",
    "    else:\n",
    "        init_epoch_idx = 0\n",
    "        init_global_step = 0\n",
    "\n",
    "else:\n",
    "    state_dict = None\n",
    "    init_epoch_idx = 0\n",
    "    init_global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3c33bf3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    }
   ],
   "source": [
    "model = MTDNNModel(\n",
    "        opt,\n",
    "        devices=args.devices,\n",
    "        num_train_step=num_all_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76602cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (args.head_probe or args.model_probe):\n",
    "    if state_dict is not None and args.resume:\n",
    "        if args.huggingface_ckpt:\n",
    "            if args.bert_model_type == 'bert-base-multilingual-cased':\n",
    "                params_to_remove = [\n",
    "                    \"cls.predictions.bias\",\n",
    "                    \"cls.predictions.transform.dense.weight\",\n",
    "                    \"cls.predictions.transform.dense.bias\",\n",
    "                    \"cls.predictions.transform.LayerNorm.weight\",\n",
    "                    \"cls.predictions.transform.LayerNorm.bias\",\n",
    "                    \"cls.predictions.decoder.weight\",\n",
    "                    \"cls.predictions.decoder.bias\"\n",
    "                ]\n",
    "            elif args.bert_model_type == 'xlm-roberta-base':\n",
    "                params_to_remove = []\n",
    "\n",
    "                # rename roberta -> bert\n",
    "                renamed_state_dict = {}\n",
    "                for n, p in state_dict.items():\n",
    "                    new_name = n.split('.')\n",
    "                    if new_name[0] == 'roberta':\n",
    "                        new_name[0] = 'bert'\n",
    "                        new_name = '.'.join(new_name)\n",
    "                        renamed_state_dict[new_name] = p\n",
    "                state_dict = renamed_state_dict\n",
    "            else:\n",
    "                params_to_remove = []\n",
    "\n",
    "            for param_name in params_to_remove:\n",
    "                if param_name in state_dict:\n",
    "                    print(f'{param_name} in state_dict, removing')\n",
    "                    del state_dict[param_name]\n",
    "                else:\n",
    "                    print(f'{param_name} not in state_dict')\n",
    "\n",
    "            _init_state_dict = model.network.state_dict()\n",
    "\n",
    "            params_to_add = [\n",
    "                    \"bert.pooler.dense.weight\",\n",
    "                    \"bert.pooler.dense.bias\",\n",
    "                    \"pooler.dense.weight\",\n",
    "                    \"pooler.dense.bias\"\n",
    "                ]\n",
    "            num_tasks = len(task_def_list)\n",
    "            for i in range(num_tasks):\n",
    "                params_to_add.extend([f\"scoring_list.{i}.weight\", f\"scoring_list.{i}.bias\"])\n",
    "\n",
    "            for param_name in params_to_add:\n",
    "                #state_dict[param_name] = _init_state_dict[param_name]\n",
    "                state_dict['state'][param_name] = _init_state_dict[param_name]\n",
    "\n",
    "            #state_dict = {'state': state_dict}\n",
    "\n",
    "        if args.jm_finetune and args.jm_finetune_new:\n",
    "            for param in ['weight', 'bias']:\n",
    "                state_dict['state'][f'scoring_list.0.{param}'] = model.network.state_dict()[f'scoring_list.0.{param}']\n",
    "        \n",
    "        model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8350401",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.head_probe:\n",
    "    print_message(logger, f'attached head probe at layer #{args.head_probe_layer+1}, head #{args.head_probe_idx+1}')\n",
    "    opt['head_idx_to_probe'] = (args.head_probe_layer, args.head_probe_idx)\n",
    "\n",
    "    # freeze all params\n",
    "    for p in model.network.parameters():\n",
    "        p.requires_grad = False\n",
    "    \n",
    "    # load model, making sure to match scoring_list params\n",
    "    if args.model_ckpt != '':\n",
    "        state_dict = torch.load(args.model_ckpt, map_location=f'cuda:{args.devices[0]}')\n",
    "        state_dict['state']['scoring_list.0.weight'] = model.network.state_dict()['scoring_list.0.weight']\n",
    "        state_dict['state']['scoring_list.0.bias'] = model.network.state_dict()['scoring_list.0.bias']\n",
    "\n",
    "        # don't need pooler weights of finetuned model if we're head_probing on a SL task\n",
    "        if task_def_list[0].task_type is TaskType.SequenceLabeling:\n",
    "            if 'pooler.dense.weight' in state_dict['state']:\n",
    "                del state_dict['state']['pooler.dense.weight']\n",
    "                del state_dict['state']['pooler.dense.bias']\n",
    "        \n",
    "        else:\n",
    "            # if loaded checkpoint is NER or POS, but head probing on a Classification task,\n",
    "            # match params.\n",
    "            # this has no effect on results, but allows you to load state dict with strict=True,\n",
    "            # which is safer.\n",
    "            if 'pooler.dense.weight' not in state_dict['state']:\n",
    "                state_dict['state']['pooler.dense.weight'] = model.network.state_dict()['pooler.dense.weight']\n",
    "                state_dict['state']['pooler.dense.bias'] = model.network.state_dict()['pooler.dense.bias']\n",
    "        \n",
    "        model.load_state_dict(state_dict)\n",
    "    \n",
    "    # then attach probing head\n",
    "    model.attach_head_probe(\n",
    "        args.head_probe_layer,\n",
    "        args.head_probe_idx,\n",
    "        n_classes=args.head_probe_n_classes,\n",
    "        sequence=args.head_probe_sequence)\n",
    "    optimizer_parameters = model._get_param_groups()\n",
    "    model._setup_optim(optimizer_parameters, None, num_all_batches)\n",
    "\n",
    "    init_epoch_idx = 0\n",
    "    init_global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7f35d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model_probe:\n",
    "    print_message(logger, 'probing whole model. Setting n_epochs to 2.')\n",
    "    args.epochs = 2\n",
    "\n",
    "    # freeze all params\n",
    "    for p in model.network.parameters():\n",
    "        p.requires_grad = False\n",
    "    \n",
    "    # load model, making sure to match scoring_list params\n",
    "    if args.model_ckpt != '':\n",
    "        print(f'model_probe, loading model ckpt from {args.model_ckpt}')\n",
    "        state_dict = torch.load(args.model_ckpt, map_location=f'cuda:{args.devices[0]}')\n",
    "        state_dict['state']['scoring_list.0.weight'] = model.network.state_dict()['scoring_list.0.weight']\n",
    "        state_dict['state']['scoring_list.0.bias'] = model.network.state_dict()['scoring_list.0.bias']\n",
    "\n",
    "        # don't need pooler weights of finetuned model if we're head_probing on a SL task\n",
    "        if task_def_list[0].task_type is TaskType.SequenceLabeling:\n",
    "            if 'pooler.dense.weight' in state_dict['state']:\n",
    "                del state_dict['state']['pooler.dense.weight']\n",
    "                del state_dict['state']['pooler.dense.bias']\n",
    "        \n",
    "        else:\n",
    "            # if model finetuned under SequenceLabeling and model probing on a task that is Classification\n",
    "            if 'pooler.dense.weight' not in state_dict['state'] and 'pooler.dense.weight' in model.network.state_dict():\n",
    "                state_dict['state']['pooler.dense.weight'] = model.network.state_dict()['pooler.dense.weight']\n",
    "                state_dict['state']['pooler.dense.bias'] = model.network.state_dict()['pooler.dense.bias']\n",
    "        \n",
    "        model.load_state_dict(state_dict)\n",
    "    \n",
    "    # then attach probing head\n",
    "    model.attach_model_probe(n_classes=args.model_probe_n_classes, sequence=args.model_probe_sequence)\n",
    "    optimizer_parameters = model._get_param_groups()\n",
    "    model._setup_optim(optimizer_parameters, None, num_all_batches)\n",
    "\n",
    "    init_epoch_idx = 0\n",
    "    init_global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e394d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_collater = Collater(\n",
    "    dropout_w=args.dropout_w,\n",
    "    encoder_type=encoder_type,\n",
    "    soft_label=False,\n",
    "    max_seq_len=args.max_seq_len,\n",
    "    do_padding=args.do_padding)\n",
    "\n",
    "multi_task_train_dataset = MultiTaskDataset(train_datasets)\n",
    "multi_task_batch_sampler = MultiTaskBatchSampler(\n",
    "                            train_datasets,\n",
    "                            args.batch_size,\n",
    "                            args.mix_opt,\n",
    "                            args.ratio,\n",
    "                            bin_on=args.bin_on,\n",
    "                            bin_size=args.bin_size,\n",
    "                            bin_grow_ratio=args.bin_grow_ratio)\n",
    "\n",
    "multi_task_train_dataloader = DataLoader(\n",
    "    multi_task_train_dataset,\n",
    "    batch_sampler=multi_task_batch_sampler,\n",
    "    collate_fn=train_collater.collate_fn,\n",
    "    pin_memory=len(args.devices)>0)\n",
    "\n",
    "train_data_lists.append(multi_task_train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "083541a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 samples out of 200\n"
     ]
    }
   ],
   "source": [
    "metric_meta = task_defs._metric_meta_map[dataset]\n",
    "datasets = ['en']\n",
    "model_type = 'bert'\n",
    "device_id = args.devices[0]\n",
    "task = Experiment[dataset.upper()]\n",
    "task_def_path = args.task_def\n",
    "\n",
    "dev_data_lst = []\n",
    "for ds in datasets:\n",
    "    data_path = f'experiments/{task.name}/{ds}/{args.bert_model_type}/{task.name.lower()}_dev.json'\n",
    "    dev_data = build_dataset(\n",
    "        data_path,\n",
    "        EncoderModelType.BERT,\n",
    "        batch_size=8,\n",
    "        max_seq_len=512,\n",
    "        task_def=TaskDefs(task_def_path).get_task_def(task.name.lower()))\n",
    "    dev_data_lst.append(dev_data)  \n",
    "\n",
    "# dump config\n",
    "dump_opt(opt, output_dir)\n",
    "\n",
    "if args.gradient_probe:\n",
    "    save_path = Path('gradient_probe_outputs').joinpath(exp_name)\n",
    "    prediction_gradient(\n",
    "        args,\n",
    "        model, \n",
    "        multi_task_train_dataloader,\n",
    "        save_path\n",
    "    )\n",
    "    #return\n",
    "\n",
    "if args.wandb:\n",
    "    wandb.init(project='soroush', name=exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef7537c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/13/2022 07:26:18 At epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/wrap.py:101: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)\n",
      "  return orig_fn(arg0, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/13/2022 07:26:19 [e5] [1/25] train loss: 0.05420 | dev score: 57.04998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/13/2022 07:26:20 [e5] [1/25] train loss: 0.04864 | dev score: 57.04998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/13/2022 07:26:20 [e5] [1/25] train loss: 0.04406 | dev score: 57.04998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/13/2022 07:26:20 [e5] [1/25] train loss: 0.03925 | dev score: 57.04998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/aadil/bert-probing/pipeline.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223132392e3137302e3231322e3333222c2275736572223a22616164696c227d/home/aadil/bert-probing/pipeline.ipynb#ch0000015vscode-remote?line=6'>7</a>\u001b[0m batch_meta, batch_data \u001b[39m=\u001b[39m Collater\u001b[39m.\u001b[39mpatch_data(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223132392e3137302e3231322e3333222c2275736572223a22616164696c227d/home/aadil/bert-probing/pipeline.ipynb#ch0000015vscode-remote?line=7'>8</a>\u001b[0m     torch\u001b[39m.\u001b[39mdevice(args\u001b[39m.\u001b[39mdevices[\u001b[39m0\u001b[39m]),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223132392e3137302e3231322e3333222c2275736572223a22616164696c227d/home/aadil/bert-probing/pipeline.ipynb#ch0000015vscode-remote?line=8'>9</a>\u001b[0m     batch_meta,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223132392e3137302e3231322e3333222c2275736572223a22616164696c227d/home/aadil/bert-probing/pipeline.ipynb#ch0000015vscode-remote?line=9'>10</a>\u001b[0m     batch_data)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223132392e3137302e3231322e3333222c2275736572223a22616164696c227d/home/aadil/bert-probing/pipeline.ipynb#ch0000015vscode-remote?line=11'>12</a>\u001b[0m task_id \u001b[39m=\u001b[39m batch_meta[\u001b[39m'\u001b[39m\u001b[39mtask_id\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223132392e3137302e3231322e3333222c2275736572223a22616164696c227d/home/aadil/bert-probing/pipeline.ipynb#ch0000015vscode-remote?line=12'>13</a>\u001b[0m model\u001b[39m.\u001b[39;49mupdate(batch_meta, batch_data)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223132392e3137302e3231322e3333222c2275736572223a22616164696c227d/home/aadil/bert-probing/pipeline.ipynb#ch0000015vscode-remote?line=14'>15</a>\u001b[0m metrics \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223132392e3137302e3231322e3333222c2275736572223a22616164696c227d/home/aadil/bert-probing/pipeline.ipynb#ch0000015vscode-remote?line=16'>17</a>\u001b[0m \u001b[39mif\u001b[39;00m (model\u001b[39m.\u001b[39mupdates \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m (args\u001b[39m.\u001b[39mlog_per_updates) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223132392e3137302e3231322e3333222c2275736572223a22616164696c227d/home/aadil/bert-probing/pipeline.ipynb#ch0000015vscode-remote?line=17'>18</a>\u001b[0m     \u001b[39m# Based on evaluate_model_against_multiple_datasets\u001b[39;00m\n",
      "File \u001b[0;32m~/bert-probing/mt_dnn/model.py:253\u001b[0m, in \u001b[0;36mMTDNNModel.update\u001b[0;34m(self, batch_meta, batch_data)\u001b[0m\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/model.py?line=248'>249</a>\u001b[0m         weight \u001b[39m=\u001b[39m batch_data[batch_meta[\u001b[39m'\u001b[39m\u001b[39mfactor\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/model.py?line=250'>251</a>\u001b[0m \u001b[39m#with autocast():\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/model.py?line=251'>252</a>\u001b[0m \u001b[39m# fw to get logits\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/aadil/bert-probing/mt_dnn/model.py?line=252'>253</a>\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmnetwork(\u001b[39m*\u001b[39;49minputs, model_probe\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_probe, head_probe\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhead_probe)\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/model.py?line=254'>255</a>\u001b[0m \u001b[39m# compute loss\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/model.py?line=255'>256</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/bert-probing/mt_dnn/matcher.py:156\u001b[0m, in \u001b[0;36mSANBertNetwork.forward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, premise_mask, hyp_mask, task_id, y_input_ids, fwd_type, embed, model_probe, head_probe)\u001b[0m\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=153'>154</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_ids, token_type_ids, attention_mask, premise_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, hyp_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, task_id\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, y_input_ids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, fwd_type\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, embed\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, model_probe\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, head_probe\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):        \n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=154'>155</a>\u001b[0m     \u001b[39massert\u001b[39;00m fwd_type \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, fwd_type\n\u001b[0;32m--> <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=155'>156</a>\u001b[0m     encode_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode(\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=156'>157</a>\u001b[0m                         input_ids,\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=157'>158</a>\u001b[0m                         token_type_ids,\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=158'>159</a>\u001b[0m                         attention_mask,\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=159'>160</a>\u001b[0m                         y_input_ids\u001b[39m=\u001b[39;49my_input_ids,\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=160'>161</a>\u001b[0m                         output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=161'>162</a>\u001b[0m                     )\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=163'>164</a>\u001b[0m     last_hidden_state, all_hidden_states, head_probe_output, model_probe_output \u001b[39m=\u001b[39m encode_outputs\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=165'>166</a>\u001b[0m     decoder_opt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder_opt[task_id]\n",
      "File \u001b[0;32m~/bert-probing/mt_dnn/matcher.py:139\u001b[0m, in \u001b[0;36mSANBertNetwork.encode\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, inputs_embeds, y_input_ids, output_hidden_states)\u001b[0m\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=136'>137</a>\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mencoder_last_hidden_state \u001b[39m# num_layers + 1 (embeddings)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=137'>138</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=138'>139</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=139'>140</a>\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=140'>141</a>\u001b[0m         token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=141'>142</a>\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=142'>143</a>\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=143'>144</a>\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=144'>145</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=146'>147</a>\u001b[0m     last_hidden_state \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mlast_hidden_state\n\u001b[1;32m    <a href='file:///home/aadil/bert-probing/mt_dnn/matcher.py?line=147'>148</a>\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mhidden_states \n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:2869\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2858'>2859</a>\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2860'>2861</a>\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2861'>2862</a>\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2862'>2863</a>\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2865'>2866</a>\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2866'>2867</a>\u001b[0m )\n\u001b[0;32m-> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2868'>2869</a>\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2869'>2870</a>\u001b[0m     embedding_output,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2870'>2871</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2871'>2872</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2872'>2873</a>\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2873'>2874</a>\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2874'>2875</a>\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2875'>2876</a>\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2876'>2877</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2877'>2878</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2878'>2879</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2879'>2880</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2881'>2882</a>\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2882'>2883</a>\u001b[0m pooled_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:2442\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2432'>2433</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2433'>2434</a>\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2434'>2435</a>\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2438'>2439</a>\u001b[0m         encoder_attention_mask,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2439'>2440</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2440'>2441</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2441'>2442</a>\u001b[0m     layer_outputs, head_probe \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2442'>2443</a>\u001b[0m         hidden_states,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2443'>2444</a>\u001b[0m         attention_mask,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2444'>2445</a>\u001b[0m         layer_head_mask,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2445'>2446</a>\u001b[0m         encoder_hidden_states,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2446'>2447</a>\u001b[0m         encoder_attention_mask,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2447'>2448</a>\u001b[0m         past_key_value,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2448'>2449</a>\u001b[0m         output_attentions,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2449'>2450</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2451'>2452</a>\u001b[0m     \u001b[39mif\u001b[39;00m head_probe:\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2452'>2453</a>\u001b[0m         head_probe_output \u001b[39m=\u001b[39m layer_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:2322\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2309'>2310</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2310'>2311</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2311'>2312</a>\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2318'>2319</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2319'>2320</a>\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2320'>2321</a>\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2321'>2322</a>\u001b[0m     self_attention_outputs, head_probe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2322'>2323</a>\u001b[0m         hidden_states,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2323'>2324</a>\u001b[0m         attention_mask,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2324'>2325</a>\u001b[0m         head_mask,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2325'>2326</a>\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2326'>2327</a>\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2327'>2328</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2328'>2329</a>\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2329'>2330</a>\u001b[0m     \u001b[39mif\u001b[39;00m head_probe:\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:2255\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2234'>2235</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2235'>2236</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2236'>2237</a>\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2242'>2243</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2243'>2244</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2244'>2245</a>\u001b[0m     self_outputs, head_probe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself(\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2245'>2246</a>\u001b[0m         hidden_states,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2246'>2247</a>\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2251'>2252</a>\u001b[0m         output_attentions,\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2252'>2253</a>\u001b[0m     )\n\u001b[0;32m-> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2254'>2255</a>\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(self_outputs[\u001b[39m0\u001b[39;49m], hidden_states)\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2255'>2256</a>\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,)\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2257'>2258</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(self_outputs) \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mor\u001b[39;00m (\u001b[39mlen\u001b[39m(self_outputs) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m head_probe):\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:2204\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2202'>2203</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states, input_tensor):\n\u001b[0;32m-> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2203'>2204</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2204'>2205</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=2205'>2206</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/wrap.py:25\u001b[0m, in \u001b[0;36mmake_cast_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/wrap.py?line=22'>23</a>\u001b[0m         \u001b[39mif\u001b[39;00m utils\u001b[39m.\u001b[39mshould_cache(kwargs[k]):\n\u001b[1;32m     <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/wrap.py?line=23'>24</a>\u001b[0m             kwargs[k] \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mcached_cast(cast_fn, kwargs[k], handle\u001b[39m.\u001b[39mcache)\n\u001b[0;32m---> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/wrap.py?line=24'>25</a>\u001b[0m new_args \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mcasted_args(cast_fn,\n\u001b[1;32m     <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/wrap.py?line=25'>26</a>\u001b[0m                              args,\n\u001b[1;32m     <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/wrap.py?line=26'>27</a>\u001b[0m                              kwargs)\n\u001b[1;32m     <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/wrap.py?line=27'>28</a>\u001b[0m \u001b[39mreturn\u001b[39;00m orig_fn(\u001b[39m*\u001b[39mnew_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/utils.py:80\u001b[0m, in \u001b[0;36mcasted_args\u001b[0;34m(cast_fn, args, kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/utils.py?line=77'>78</a>\u001b[0m new_args \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/utils.py?line=78'>79</a>\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m args:\n\u001b[0;32m---> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/utils.py?line=79'>80</a>\u001b[0m     \u001b[39mif\u001b[39;00m is_fp_tensor(x):\n\u001b[1;32m     <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/utils.py?line=80'>81</a>\u001b[0m         new_args\u001b[39m.\u001b[39mappend(cast_fn(x))\n\u001b[1;32m     <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/utils.py?line=81'>82</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/utils.py:21\u001b[0m, in \u001b[0;36mis_fp_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/utils.py?line=18'>19</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/utils.py?line=19'>20</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/utils.py?line=20'>21</a>\u001b[0m \u001b[39mreturn\u001b[39;00m compat\u001b[39m.\u001b[39;49mis_tensor_like(x) \u001b[39mand\u001b[39;00m compat\u001b[39m.\u001b[39mis_floating_point(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/compat.py:20\u001b[0m, in \u001b[0;36mis_tensor_like\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/compat.py?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_tensor_like\u001b[39m(x):\n\u001b[0;32m---> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/compat.py?line=19'>20</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mis_tensor(x) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(x, torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mVariable)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/__init__.py:290\u001b[0m, in \u001b[0;36mis_tensor\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/__init__.py?line=272'>273</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_tensor\u001b[39m(obj):\n\u001b[1;32m    <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/__init__.py?line=273'>274</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Returns True if `obj` is a PyTorch tensor.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/__init__.py?line=274'>275</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/__init__.py?line=275'>276</a>\u001b[0m \u001b[39m    Note that this function is simply doing ``isinstance(obj, Tensor)``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/__init__.py?line=287'>288</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/__init__.py?line=288'>289</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/__init__.py?line=289'>290</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, torch\u001b[39m.\u001b[39;49mTensor)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# main training loop\n",
    "start_time = time.time()\n",
    "for epoch in range(init_epoch_idx, init_epoch_idx+args.epochs):        \n",
    "    print_message(logger, f'At epoch {epoch}', level=1)\n",
    "    \n",
    "    for (batch_meta, batch_data) in multi_task_train_dataloader:\n",
    "        batch_meta, batch_data = Collater.patch_data(\n",
    "            torch.device(args.devices[0]),\n",
    "            batch_meta,\n",
    "            batch_data)\n",
    "\n",
    "        task_id = batch_meta['task_id']\n",
    "        model.update(batch_meta, batch_data)\n",
    "\n",
    "        metrics = []\n",
    "\n",
    "        if (model.updates - 1) % (args.log_per_updates) == 0:\n",
    "            # Based on evaluate_model_against_multiple_datasets\n",
    "            for dev_data in dev_data_lst:\n",
    "                metric = get_metric(\n",
    "                    model, \n",
    "                    dev_data, \n",
    "                    metric_meta, \n",
    "                    task_def.task_type, \n",
    "                    device_id, \n",
    "                    task_def.label_vocab.ind2tok, \n",
    "                    model_probe=args.model_probe, \n",
    "                    head_probe=args.head_probe\n",
    "                )[0]\n",
    "                metric = metric[args.metric_of_choice]\n",
    "                metrics.append(metric)\n",
    "\n",
    "            print_message(logger, f\"[e{epoch}] [{model.updates % n_batch_per_epoch}/{n_batch_per_epoch}] train loss: {model.train_loss.avg:.5f} | dev score: {metrics[0]:.5f}\")\n",
    "\n",
    "            if args.wandb:\n",
    "                wandb.log({\n",
    "                    'train/loss': model.train_loss.avg,\n",
    "                    'dev/score': metrics[0],\n",
    "                    'global_step': init_global_step + model.updates,\n",
    "                    'epoch': epoch\n",
    "                })\n",
    "\n",
    "    model_file = save_checkpoint(model, epoch, output_dir)\n",
    "    print_message(logger, f'Saving mt-dnn model to {model_file}')\n",
    "print_message(logger, f'Total time taken: {time.time()-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06255135",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dev_data in dev_data_lst:\n",
    "    metric = get_metric(\n",
    "        model, \n",
    "        dev_data, \n",
    "        (Metric.SeqEval,), \n",
    "        task_def.task_type, \n",
    "        device_id, \n",
    "        task_def.label_vocab.ind2tok, \n",
    "        model_probe=args.model_probe, \n",
    "        head_probe=args.head_probe\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acaa397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "      PER     0.0110    0.0006    0.0012      4635\n",
      "      LOC     0.0467    0.0029    0.0055      4834\n",
      "      ORG     0.0384    0.0081    0.0134      4677\n",
      "\n",
      "micro avg     0.0030    0.0039    0.0034     14146\n",
      "macro avg     0.0323    0.0039    0.0067     14146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metric['SeqEval'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4509d32d",
   "metadata": {},
   "source": [
    "# Generate model probing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37947fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_model_probe_results import get_model_probe_scores, get_model_probe_final_score, combine_all_model_probe_scores\n",
    "from experiments.exp_def import (\n",
    "    Experiment,\n",
    "    LingualSetting,\n",
    "    TaskDefs,\n",
    ")\n",
    "from data_utils.metrics import Metric\n",
    "from utils import base_construct_model, create_heatmap\n",
    "from mt_dnn.model import MTDNNModel\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28720767",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = 0\n",
    "finetuned_task = Experiment.FINER\n",
    "finetuned_setting = LingualSetting.CROSS\n",
    "probe_setting = LingualSetting.CROSS\n",
    "probe_task = Experiment.SCITAIL\n",
    "helper = '_base' if finetuned_setting is LingualSetting.BASE else ''\n",
    "model_ckpt = list(Path(f'checkpoint/{finetuned_task.name}{helper}_{probe_task.name}').rglob('*.pt'))[0]\n",
    "out_file_name = 'results.csv'\n",
    "metric_of_choice = 'F1'\n",
    "seed = 2018\n",
    "batch_size = 64\n",
    "max_seq_len = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ed16cc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_probe_outputs/mBERT\n",
      "data from experiments/SCITAIL/en/bert-base-cased/scitail_test.json\n",
      "Loaded 2126 samples out of 2126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mBERT -> SCITAIL [en], probe setting: cross\n",
      "loading from checkpoint/COARSE_base_SCITAIL/model_1_738.pt\n"
     ]
    }
   ],
   "source": [
    "get_model_probe_scores(\n",
    "    finetuned_task,\n",
    "    finetuned_setting,\n",
    "    probe_setting,\n",
    "    probe_task,\n",
    "    model_ckpt,\n",
    "    out_file_name,\n",
    "    metric_of_choice,\n",
    "    device_id,\n",
    "    'en',\n",
    "    seed,\n",
    "    batch_size,\n",
    "    max_seq_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9b9468f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WNLI</th>\n",
       "      <th>SCITAIL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>41.666667</td>\n",
       "      <td>74.9266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>41.666667</td>\n",
       "      <td>74.9266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           WNLI  SCITAIL\n",
       "2018  41.666667  74.9266\n",
       "2019  41.666667  74.9266"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/aadil/bert-probing/model_probe_outputs/FINER_cross/results.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72c99e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3\n",
       "2018  1.0  2.0  3.0  4.0\n",
       "2019  4.0  5.0  6.0  7.0\n",
       "2020  6.0  7.0  8.0  9.0\n",
       "2021  NaN  NaN  NaN  NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = np.array([[1,2,3,4],[4,5,6,7],[6,7,8,9]])\n",
    "df = pd.DataFrame(data)\n",
    "df.index = [2018,2019,2020]\n",
    "df.loc[2021] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee587945",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_probe_final_score(Experiment.COARSE, LingualSetting.CROSS)\n",
    "get_model_probe_final_score(Experiment.FINER, LingualSetting.CROSS)\n",
    "combine_all_model_probe_scores(mean=True, std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c516190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>GOEMOTIONS</th>\n",
       "      <th>NER</th>\n",
       "      <th>POS</th>\n",
       "      <th>SST5</th>\n",
       "      <th>PAWSX</th>\n",
       "      <th>COLA</th>\n",
       "      <th>MRPC</th>\n",
       "      <th>SCITAIL</th>\n",
       "      <th>WNLI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COARSE_cross</td>\n",
       "      <td>-1.145294</td>\n",
       "      <td>-4.382786</td>\n",
       "      <td>-2.357250</td>\n",
       "      <td>-0.902314</td>\n",
       "      <td>-0.470136</td>\n",
       "      <td>-1.479455</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>1.277464</td>\n",
       "      <td>16.361873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FINER_cross</td>\n",
       "      <td>0.243428</td>\n",
       "      <td>-5.268007</td>\n",
       "      <td>-2.099952</td>\n",
       "      <td>3.035971</td>\n",
       "      <td>-0.817050</td>\n",
       "      <td>4.178522</td>\n",
       "      <td>-0.286238</td>\n",
       "      <td>1.444049</td>\n",
       "      <td>7.075630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  GOEMOTIONS       NER       POS      SST5     PAWSX      COLA  \\\n",
       "0  COARSE_cross   -1.145294 -4.382786 -2.357250 -0.902314 -0.470136 -1.479455   \n",
       "1   FINER_cross    0.243428 -5.268007 -2.099952  3.035971 -0.817050  4.178522   \n",
       "\n",
       "       MRPC   SCITAIL       WNLI  \n",
       "0  0.003473  1.277464  16.361873  \n",
       "1 -0.286238  1.444049   7.075630  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.read_csv('/home/aadil/bert-probing/model_probe_outputs/final_results_mean.csv')\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7354639e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>GOEMOTIONS</th>\n",
       "      <th>NER</th>\n",
       "      <th>POS</th>\n",
       "      <th>SST5</th>\n",
       "      <th>PAWSX</th>\n",
       "      <th>COLA</th>\n",
       "      <th>MRPC</th>\n",
       "      <th>SCITAIL</th>\n",
       "      <th>WNLI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COARSE_cross</td>\n",
       "      <td>-1.018348</td>\n",
       "      <td>-4.288561</td>\n",
       "      <td>-1.754153</td>\n",
       "      <td>-1.263975</td>\n",
       "      <td>-0.214446</td>\n",
       "      <td>-1.476020</td>\n",
       "      <td>0.105056</td>\n",
       "      <td>2.254502</td>\n",
       "      <td>14.915966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FINER_cross</td>\n",
       "      <td>1.187120</td>\n",
       "      <td>-5.611468</td>\n",
       "      <td>-1.029442</td>\n",
       "      <td>5.016816</td>\n",
       "      <td>-0.460245</td>\n",
       "      <td>6.776983</td>\n",
       "      <td>-0.498211</td>\n",
       "      <td>1.948544</td>\n",
       "      <td>9.523810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  GOEMOTIONS       NER       POS      SST5     PAWSX      COLA  \\\n",
       "0  COARSE_cross   -1.018348 -4.288561 -1.754153 -1.263975 -0.214446 -1.476020   \n",
       "1   FINER_cross    1.187120 -5.611468 -1.029442  5.016816 -0.460245  6.776983   \n",
       "\n",
       "       MRPC   SCITAIL       WNLI  \n",
       "0  0.105056  2.254502  14.915966  \n",
       "1 -0.498211  1.948544   9.523810  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.read_csv('/home/aadil/bert-probing/model_probe_outputs_history/seed_2018_only/final_results_mean.csv')\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72239b2",
   "metadata": {},
   "source": [
    "# Automate model probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d4da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = {task_1: {parameter_1: value, ...}, ...}\n",
    "for seed in [2019]:\n",
    "    finetune COARSE_cross and save COARSE_base with seed\n",
    "    (python train.py --devices 2 --exp_name COARSE_cross --dataset_name COARSE/en --wandb --epochs 5 --batch_size 16 --learning_rate 5e-5 --grad_accumulation_step 4 --bert_model_type bert-base-cased --fp16 --metric_of_choice MCC --resume --huggingface_ckpt --model_ckpt /home/aadil/mt-dnn/mt_dnn_models/bert_model_base_cased.pt)\n",
    "    finetune FINER_cross with seed\n",
    "    (python train.py --devices 2 --exp_name COARSE_cross --dataset_name COARSE/en --wandb --epochs 5 --batch_size 16 --learning_rate 5e-5 --grad_accumulation_step 4 --bert_model_type bert-base-cased --fp16 --metric_of_choice MCC --resume --huggingface_ckpt --model_ckpt /home/aadil/mt-dnn/mt_dnn_models/bert_model_base_cased.pt)\n",
    "    for task in DOWNSTREAM TASKS:\n",
    "        model probe COARSE_base_{task} with specs\n",
    "        model probe COARSE_{task} with specs\n",
    "        model probe COARSE_{task} with specs\n",
    "        (python train.py --devices 2 --model_probe --model_probe_n_classes 2 --exp_name COARSE_PAWS --dataset_name PAWSX/en --wandb --epochs 2 --batch_size 64 --learning_rate 5e-3 --bert_model_type bert-base-cased --model_ckpt checkpoint/COARSE_cross/model_4_625.pt --metric_of_choice F1MAC --fp16)\n",
    "        run get_model_probe_scores(...)\n",
    "    delete all .pt files from checkpoint folder\n",
    "get_model_probe_final_score(Experiment.COARSE, LingualSetting.CROSS)\n",
    "get_model_probe_final_score(Experiment.FINER, LingualSetting.CROSS)\n",
    "combine_all_model_probe_scores(mean=True, std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdb62c6",
   "metadata": {},
   "source": [
    "# Fix MRPC test set labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b176e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "with open('/home/aadil/mt-dnn/data/MRPC/msr_paraphrase_test.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            labels.append(int(line.strip().split('\\t')[0]))\n",
    "        except:\n",
    "            pass\n",
    "lines = []\n",
    "with open('/home/aadil/mt-dnn/data/canonical_data/mrpc_test.tsv', 'r') as file:\n",
    "    for line, label in zip(file, labels):\n",
    "        items = line.split('\\t')\n",
    "        items[1] = str(label)\n",
    "        lines.append('\\t'.join(items))\n",
    "with open('/home/aadil/mt-dnn/data/canonical_data/mrpc_test_replacement.tsv', 'w') as file:\n",
    "    file.writelines(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c3af6",
   "metadata": {},
   "source": [
    "# Loading latest coarsegrained/finergrained datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124f3370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5b92622",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['train', 'dev', 'test']:\n",
    "    df = pd.read_csv(f'./drive-download-20220516T122116Z-001/intl_{split}_recleaned.csv')\n",
    "    df['text'] = df['text'].str.replace('\\n', ' ')\n",
    "    df.to_csv(f'./experiments/COARSE/en/coarse_{split}.tsv', sep='\\t', columns=['place', 'text'], index=True, header=False)\n",
    "for split in ['train', 'dev', 'test']:\n",
    "    df = pd.read_csv(f'./drive-download-20220516T122116Z-001/us_{split}_recleaned.csv')\n",
    "    df['text'] = df['text'].str.replace('\\n', ' ')\n",
    "    df.to_csv(f'./experiments/FINER/en/finer_{split}.tsv', sep='\\t', columns=['place', 'text'], index=True, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08706fc1",
   "metadata": {},
   "source": [
    "# Reformatting SST2 and creating EMOTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f468fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cb352d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates something rather beautiful about human nature</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remains utterly satisfied to remain the same throughout</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the filmmakers could dredge up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67344</th>\n",
       "      <td>a delightful comedy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67345</th>\n",
       "      <td>anguish , anger and frustration</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67346</th>\n",
       "      <td>at achieving the modest , crowd-pleasing goals it sets for itself</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67347</th>\n",
       "      <td>a patient viewer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67348</th>\n",
       "      <td>this new jangle of noise , mayhem and stupidity must be a serious contender for the title .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67349 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           sentence  \\\n",
       "0                                                      hide new secretions from the parental units    \n",
       "1                                                              contains no wit , only labored gags    \n",
       "2         that loves its characters and communicates something rather beautiful about human nature    \n",
       "3                                          remains utterly satisfied to remain the same throughout    \n",
       "4                         on the worst revenge-of-the-nerds clichés the filmmakers could dredge up    \n",
       "...                                                                                             ...   \n",
       "67344                                                                          a delightful comedy    \n",
       "67345                                                              anguish , anger and frustration    \n",
       "67346                            at achieving the modest , crowd-pleasing goals it sets for itself    \n",
       "67347                                                                             a patient viewer    \n",
       "67348  this new jangle of noise , mayhem and stupidity must be a serious contender for the title .    \n",
       "\n",
       "       label  \n",
       "0          0  \n",
       "1          0  \n",
       "2          1  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "67344      1  \n",
       "67345      0  \n",
       "67346      1  \n",
       "67347      1  \n",
       "67348      0  \n",
       "\n",
       "[67349 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../mt-dnn/data/SST-2/train.tsv', sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d0a8399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_data(path, task_name, out_dir):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for split in ['train', 'validation', 'test']:\n",
    "        final_out_file = out_dir.joinpath(f'{task_name}_{split if split != \"validation\" else \"dev\"}.tsv')\n",
    "        out_file = out_dir.joinpath(f'{task_name}_{split if split != \"validation\" else \"dev\"}_tmp.json')\n",
    "\n",
    "        if Path(final_out_file).is_file():\n",
    "            continue\n",
    "        \n",
    "        if not Path(out_file).is_file():\n",
    "            dataset = load_dataset(path, split=split)\n",
    "            dataset.to_json(out_file)\n",
    "        \n",
    "        # load and save as tsv in mtdnn format\n",
    "        df = Dataset.from_json(str(out_file))\n",
    "        with open(final_out_file, 'w') as f:\n",
    "            for i, row in enumerate(df):\n",
    "                text = row['text']\n",
    "                label = int(row['label'])\n",
    "                f.write(f'{i}\\t{label}\\t{text}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c4151",
   "metadata": {},
   "outputs": [],
   "source": [
    "_prepare_data('gpt3mix/sst2', 'sst2', Path('/home/aadil/bert-probing/experiments/SST2/en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf3425",
   "metadata": {},
   "outputs": [],
   "source": [
    "_prepare_data('emotion', 'emotion', Path('/home/aadil/bert-probing/experiments/EMOTION/en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5387ecf3",
   "metadata": {},
   "source": [
    "# Attention Head, Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f5ddc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/pyprof/__init__.py:5: FutureWarning: pyprof will be removed by the end of June, 2022\n",
      "  warnings.warn(\"pyprof will be removed by the end of June, 2022\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from experiments.exp_def import LingualSetting, Experiment, TaskDef, TaskDefs\n",
    "from pathlib import Path\n",
    "from mt_dnn.model import MTDNNModel\n",
    "from mt_dnn.batcher import SingleTaskDataset, Collater\n",
    "from data_utils.task_def import EncoderModelType\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import einops\n",
    "from apex import amp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import BertTokenizer\n",
    "import string\n",
    "import numpy as np\n",
    "from attention_flow import get_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31dd4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [0, 1]\n",
    "batch_size = 8\n",
    "bert_model_type = 'bert-base-cased'\n",
    "font_scale = 0.7\n",
    "figure_size = (15, 7)\n",
    "cbar = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "039c4187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_file, task_def, language):\n",
    "    \"\"\"\n",
    "    Create the test dataloader to use.\n",
    "\n",
    "    Args:\n",
    "    data_file: The JSON test data file\n",
    "    task_def: Path to the task_def.\n",
    "    language: Specific language to use.\n",
    "    \"\"\"\n",
    "    test_data_set = SingleTaskDataset(\n",
    "        data_file,\n",
    "        is_train=False,\n",
    "        task_def=task_def,\n",
    "    )\n",
    "\n",
    "    collater = Collater(is_train=False, encoder_type=EncoderModelType.BERT)\n",
    "    test_data = DataLoader(\n",
    "        test_data_set,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collater.collate_fn,\n",
    "        pin_memory=True)\n",
    "\n",
    "    return test_data\n",
    "\n",
    "def create_model(finetuned_task: Experiment, setting: LingualSetting, device_id: int):\n",
    "    \"\"\"\n",
    "    Create the MT-DNN model, finetuend on finetuned_task in the {base, cross}-lingual setting.\n",
    "    \"\"\"\n",
    "    checkpoint_dir = Path('checkpoint').joinpath(f'{finetuned_task.name}_{setting.name.lower()}')\n",
    "    checkpoint_file = list(checkpoint_dir.rglob('*.pt'))[0]\n",
    "    state_dict = torch.load(checkpoint_file)\n",
    "    del state_dict['optimizer']\n",
    "\n",
    "    language = 'en'\n",
    "    task_def_path = Path(f'experiments').joinpath(\n",
    "        finetuned_task.name,\n",
    "        language,\n",
    "        'task_def.yaml')\n",
    "    task_def = TaskDefs(task_def_path).get_task_def(finetuned_task.name.lower())\n",
    "    task_def_list = [task_def]\n",
    "    config = state_dict['config']\n",
    "    config['task_def_list'] = task_def_list\n",
    "\n",
    "    model = MTDNNModel(config, state_dict=state_dict, devices=[device_id])\n",
    "    model.network.eval()\n",
    "\n",
    "    data_file = Path(f'experiments/{finetuned_task.name}/').joinpath(language, bert_model_type, f'{finetuned_task.name.lower()}_test.json')\n",
    "    test_data = load_data(data_file, task_def, language)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        attentions_lst = []\n",
    "        input_ids_lst = []\n",
    "        for batch_meta, batch_data in tqdm(test_data):\n",
    "            attentions, input_ids = get_attention(model, batch_meta, batch_data, device_id)\n",
    "            # stack and rearrange to b, n_layers, n_heads, seq_len, seq_len\n",
    "            attentions = torch.stack(attentions, dim=0)\n",
    "            attentions = einops.rearrange(attentions, 'l b h x y -> b l h x y')\n",
    "            attentions_lst.append(attentions)\n",
    "            input_ids_lst.append(input_ids)\n",
    "    \n",
    "    return attentions_lst, input_ids_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35a9ffef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/pyprof/__init__.py:5: FutureWarning: pyprof will be removed by the end of June, 2022\n",
      "  warnings.warn(\"pyprof will be removed by the end of June, 2022\", FutureWarning)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"run_bertology.py\", line 434, in <module>\n",
      "    main()\n",
      "  File \"run_bertology.py\", line 409, in main\n",
      "    model = MTDNNModel(opt, state_dict=state_dict, devices=[device])\n",
      "  File \"/home/aadil/bert-probing/mt_dnn/model.py\", line 35, in __init__\n",
      "    model = SANBertNetwork(opt)\n",
      "  File \"/home/aadil/bert-probing/mt_dnn/matcher.py\", line 33, in __init__\n",
      "    self.bert = model_class.from_pretrained(opt['init_checkpoint'], cache_dir=opt['transformer_cache'])\n",
      "  File \"/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 1173, in from_pretrained\n",
      "    model = cls(config, *model_args, **model_kwargs)\n",
      "  File \"/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 2744, in __init__\n",
      "    self.encoder = BertEncoder(config)\n",
      "  File \"/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 2389, in __init__\n",
      "    self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
      "  File \"/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 2389, in <listcomp>\n",
      "    self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
      "  File \"/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 2301, in __init__\n",
      "    self.attention = BertAttention(config)\n",
      "  File \"/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 2213, in __init__\n",
      "    self.self = BertSelfAttention(config)\n",
      "  File \"/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 2060, in __init__\n",
      "    self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
      "  File \"/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 90, in __init__\n",
      "    self.reset_parameters()\n",
      "  File \"/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 96, in reset_parameters\n",
      "    init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
      "  File \"/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/init.py\", line 410, in kaiming_uniform_\n",
      "    return tensor.uniform_(-bound, bound)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python run_bertology.py --seed 2018 --task coarse --task_def 'experiments/COARSE/en/task_def.yaml' --checkpoint 'checkpoint/COARSE_cross/model_4_125.pt' --output_dir 'bertviz_outputs/COARSE_cross' --prep_input 'experiments/COARSE/en/bert-base-cased/coarse_test.json' --cuda True --batch_size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7844963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "Loaded 200 samples out of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 68.04it/s]\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Loaded 200 samples out of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 64.94it/s]\n"
     ]
    }
   ],
   "source": [
    "base_attentions, input_ids = create_model(Experiment.FINER, LingualSetting.BASE, 0)\n",
    "finer_attentions, input_ids = create_model(Experiment.FINER, LingualSetting.CROSS, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b172f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b97a9892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(attention_maps, input_ids, i, punctuation=False, special_tokens=False): \n",
    "    remove_ids = [0] # 0 -> PAD\n",
    "    if not (punctuation or special_tokens):\n",
    "        if not punctuation:\n",
    "            remove_ids.extend([tokenizer.vocab[c] for c in string.punctuation if c in tokenizer.vocab])\n",
    "        if not special_tokens:\n",
    "            remove_ids.extend([101, 102]) # 101 -> CLS, 102 -> SEP\n",
    "    remove_ids = torch.tensor(remove_ids)\n",
    "    mask = ~torch.isin(input_ids[i//batch_size][i%batch_size].cpu(), remove_ids)\n",
    "    return attention_maps[i//batch_size][i%batch_size, :, :, mask, :][:, :, :, mask].cpu().numpy(), input_ids[i//batch_size][i%batch_size, mask].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e53f2820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The consumer price index is expected to show a moderate gain in inflation of 0 4 in February or 0 1 when excluding food and energy The market is closely watching the number as debate swirls around whether a surge in the economy – boosted by fiscal stimulus – will lead to high inflation'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, ip = sample(base_attentions, input_ids, 133)\n",
    "tokenizer.decode(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edeb84fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25,  82, 133,  91, 122, 197, 107, 149,  45,  90,  53, 173, 158,\n",
       "        84,  51, 193,  41,  92,  43,  55, 136, 174, 183,  39,  80, 129,\n",
       "         0,  15, 188,  65,   7, 187, 110, 199,  17, 152, 160, 141,   4,\n",
       "       165, 140,  12,  75, 117,   5, 150, 121,  62,  33, 125, 102, 196,\n",
       "       137,  83,  87, 159,   3,  60, 186,  79, 161, 198, 124,  48, 166,\n",
       "       126, 175,  38, 154,  20,  23, 104,  99,  16,  69, 182,  47,  64,\n",
       "       131,  94, 103, 190, 100,  29, 191, 108,  34,   1,  86,  71, 134,\n",
       "       192,  95, 132,  89,  67,  26,  52, 146, 118,  28, 109,   9, 144,\n",
       "        46,  81,  49,  77,  42, 167,  21, 155, 189, 153, 112,  78, 138,\n",
       "       168,  13, 184, 195, 172,  24, 115,  40, 105,  37,  56, 148, 101,\n",
       "        35, 171,  85, 116,  59,  72,  66, 194, 170, 177,  58,  14,  88,\n",
       "        98,  30, 114,  32,  10, 113, 106,  76, 120,  63,  97, 157, 135,\n",
       "         6,  57, 127, 156,  11,  70, 178,  19,  36, 176,   2,  22,  73,\n",
       "       180, 151, 169, 163,  31, 139,  68, 164, 119, 143, 179,  96, 181,\n",
       "        93,  50, 185, 123,  44, 162,  54, 145,   8,  61,  18, 111, 130,\n",
       "       147,  27, 128, 142,  74])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = []\n",
    "idx = 0\n",
    "while True:\n",
    "    #if idx%10 == 0: print(idx)\n",
    "    try:\n",
    "        _, ip = sample(base_attentions, input_ids, idx)\n",
    "        lengths.append(ip.shape[0])\n",
    "        idx += 1\n",
    "    except:\n",
    "        break\n",
    "order = np.argsort(lengths)\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa08704b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "858ea352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 135\n",
    "layer, head = 12, 2\n",
    "ba, ip = sample(base_attentions, input_ids, idx)\n",
    "fa, ip = sample(coarse_attentions, input_ids, idx)\n",
    "tokens = tokenizer.convert_ids_to_tokens(ip)\n",
    "sns.set(font_scale=font_scale)\n",
    "plt.rcParams['figure.figsize'] = figure_size\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "sns.heatmap(ba[layer-1, head-1], ax=axes[0], cmap=\"Blues\", xticklabels=tokens, yticklabels=tokens, cbar=cbar)\n",
    "axes[0].set_title('Pre-trained')\n",
    "sns.heatmap(fa[layer-1, head-1], ax=axes[1], cmap=\"Blues\", xticklabels=tokens, yticklabels=tokens, cbar=cbar)\n",
    "axes[1].set_title('Fine-tuned')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5149ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e7d90f60a8b628b70394d2a2332723d4e001ac85fbb52530832d6774e8389f6"
  },
  "kernelspec": {
   "display_name": "Python [conda env:venv3.8] *",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
