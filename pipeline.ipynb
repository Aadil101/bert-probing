{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6006e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/pyprof/__init__.py:5: FutureWarning: pyprof will be removed by the end of June, 2022\n",
      "  warnings.warn(\"pyprof will be removed by the end of June, 2022\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "torch.cuda.empty_cache()\n",
    "from pretrained_models import *\n",
    "\n",
    "from experiments.exp_def import TaskDefs, Experiment\n",
    "from data_utils.log_wrapper import create_logger\n",
    "from data_utils.task_def import EncoderModelType\n",
    "from data_utils.utils import set_environment\n",
    "\n",
    "from mt_dnn.model import MTDNNModel\n",
    "from mt_dnn.batcher import (\n",
    "    SingleTaskDataset,\n",
    "    MultiTaskDataset,\n",
    "    Collater,\n",
    "    MultiTaskBatchSampler\n",
    ")\n",
    "from train_utils import (\n",
    "    dump_opt,\n",
    "    print_message,\n",
    "    save_checkpoint\n",
    ")\n",
    "from gradient_probing import prediction_gradient\n",
    "import wandb\n",
    "\n",
    "from evaluate import get_metric, build_dataset, evaluate_model_against_multiple_datasets\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc67e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_config(parser):\n",
    "    # SET THESE\n",
    "    ##############\n",
    "    parser.add_argument('--multi_gpu_on', action='store_true')\n",
    "    parser.add_argument('--devices', nargs='+')\n",
    "\n",
    "    # head probing\n",
    "    parser.add_argument('--head_probe', action='store_true')\n",
    "    parser.add_argument('--head_probe_layer', type=int)\n",
    "    parser.add_argument('--head_probe_idx', type=int)\n",
    "    parser.add_argument('--head_probe_n_classes', type=int)\n",
    "\n",
    "    # model probing\n",
    "    parser.add_argument('--model_probe', action='store_true')\n",
    "    parser.add_argument('--model_probe_n_classes', type=int)\n",
    "\n",
    "    # gradient probing\n",
    "    parser.add_argument('--gradient_probe', action='store_true')\n",
    "\n",
    "    # finetuning after joint modeling\n",
    "    parser.add_argument('--jm_finetune', action='store_true')\n",
    "    parser.add_argument('--jm_finetune_new', action='store_true') # if task does not exist in 1st stage finetuning\n",
    "    parser.add_argument('--jm_task_id', type=int, default=0) # if task exists from 1st stage finetuning\n",
    "    ##############\n",
    "\n",
    "    # DON\"T NEED THESE\n",
    "    ##############\n",
    "    parser.add_argument('--update_bert_opt', default=0, type=int)\n",
    "    parser.add_argument('--mem_cum_type', type=str, default='simple',\n",
    "                        help='bilinear/simple/defualt')\n",
    "    parser.add_argument('--answer_num_turn', type=int, default=5)\n",
    "    parser.add_argument('--answer_mem_drop_p', type=float, default=0.1)\n",
    "    parser.add_argument('--answer_att_hidden_size', type=int, default=128)\n",
    "    parser.add_argument('--answer_att_type', type=str, default='bilinear',\n",
    "                        help='bilinear/simple/defualt')\n",
    "    parser.add_argument('--answer_rnn_type', type=str, default='gru',\n",
    "                        help='rnn/gru/lstm')\n",
    "    parser.add_argument('--answer_sum_att_type', type=str, default='bilinear',\n",
    "                        help='bilinear/simple/defualt')\n",
    "    parser.add_argument('--answer_merge_opt', type=int, default=1)\n",
    "    parser.add_argument('--answer_mem_type', type=int, default=1)\n",
    "    parser.add_argument('--max_answer_len', type=int, default=10)\n",
    "    parser.add_argument('--answer_dropout_p', type=float, default=0.1)\n",
    "    parser.add_argument('--answer_weight_norm_on', action='store_true')\n",
    "    parser.add_argument('--dump_state_on', action='store_true')\n",
    "    parser.add_argument('--answer_opt', type=int, default=1, help='0,1')\n",
    "    parser.add_argument('--pooler_actf', type=str, default='tanh',\n",
    "                        help='tanh/relu/gelu')\n",
    "    parser.add_argument('--mtl_opt', type=int, default=0)\n",
    "    parser.add_argument('--ratio', type=float, default=0)\n",
    "    parser.add_argument('--mix_opt', type=int, default=0)\n",
    "    parser.add_argument('--max_seq_len', type=int, default=512)\n",
    "    parser.add_argument('--init_ratio', type=float, default=1)\n",
    "    parser.add_argument('--encoder_type', type=int, default=EncoderModelType.BERT)\n",
    "    parser.add_argument('--num_hidden_layers', type=int, default=-1)\n",
    "\n",
    "    # BERT pre-training\n",
    "    parser.add_argument('--bert_model_type', type=str, default='bert-base-cased')\n",
    "    parser.add_argument('--init_checkpoint', type=str, default='bert-base-cased')\n",
    "    parser.add_argument('--do_lower_case', action='store_true')\n",
    "    parser.add_argument('--masked_lm_prob', type=float, default=0.15)\n",
    "    parser.add_argument('--short_seq_prob', type=float, default=0.2)\n",
    "    parser.add_argument('--max_predictions_per_seq', type=int, default=128)\n",
    "\n",
    "    # bin samples\n",
    "    parser.add_argument('--bin_on', action='store_true')\n",
    "    parser.add_argument('--bin_size', type=int, default=64)\n",
    "    parser.add_argument('--bin_grow_ratio', type=int, default=0.5)\n",
    "\n",
    "    # dist training\n",
    "    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n",
    "    parser.add_argument(\"--world_size\", type=int, default=1, help=\"For distributed training: world size\")\n",
    "    parser.add_argument(\"--master_addr\", type=str, default=\"localhost\")\n",
    "    parser.add_argument(\"--master_port\", type=str, default=\"6600\")\n",
    "    parser.add_argument(\"--backend\", type=str, default=\"nccl\")\n",
    "    ##############\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "def data_config(parser):\n",
    "    # SET THESE\n",
    "    ############\n",
    "    parser.add_argument('--exp_name', default='', help='experiment name')\n",
    "    parser.add_argument('--dataset_name', default='', help='dataset name')\n",
    "    parser.add_argument('--wandb', action='store_true')\n",
    "    ############\n",
    "\n",
    "    # DON'T NEED THESE\n",
    "    ############\n",
    "    parser.add_argument('--log_file', default='mt-dnn.log', help='path for log file.')\n",
    "    parser.add_argument('--data_sort_on', action='store_true')\n",
    "    parser.add_argument('--mkd-opt', type=int, default=0, \n",
    "                        help=\">0 to turn on knowledge distillation, requires 'softlabel' column in input data\")\n",
    "    parser.add_argument('--do_padding', action='store_true')\n",
    "    ############\n",
    "    return parser\n",
    "\n",
    "\n",
    "def train_config(parser):\n",
    "    # SET THESE\n",
    "    ############\n",
    "    parser.add_argument('--epochs', type=int, default=6)\n",
    "    parser.add_argument('--batch_size', type=int, default=8)\n",
    "\n",
    "    # loading\n",
    "    parser.add_argument(\"--model_ckpt\", default='', type=str)\n",
    "    parser.add_argument(\"--resume\", action='store_true')\n",
    "    parser.add_argument('--huggingface_ckpt', action='store_true')\n",
    "\n",
    "    # metrics\n",
    "    parser.add_argument('--metric_of_choice', default='F1', type=str)\n",
    "    ############\n",
    "\n",
    "    # DON'T NEED THESE\n",
    "    ############\n",
    "    parser.add_argument('--cuda', type=bool, default=torch.cuda.is_available(),\n",
    "                        help='whether to use GPU acceleration.')\n",
    "    parser.add_argument('--log_per_updates', type=int, default=100)\n",
    "    parser.add_argument('--save_per_updates', type=int, default=10000)\n",
    "    parser.add_argument('--save_per_updates_on', action='store_true')\n",
    "    parser.add_argument('--optimizer', default='adamax',\n",
    "                        help='supported optimizer: adamax, sgd, adadelta, adam')\n",
    "    parser.add_argument('--grad_clipping', type=float, default=0)\n",
    "    parser.add_argument('--global_grad_clipping', type=float, default=1.0)\n",
    "    parser.add_argument('--weight_decay', type=float, default=0)\n",
    "    parser.add_argument('--learning_rate', type=float, default=5e-5)\n",
    "    parser.add_argument('--momentum', type=float, default=0)\n",
    "    parser.add_argument('--warmup', type=float, default=0.1)\n",
    "    parser.add_argument('--warmup_schedule', type=str, default='warmup_linear')\n",
    "    parser.add_argument('--adam_eps', type=float, default=1e-6)\n",
    "\n",
    "    parser.add_argument('--vb_dropout', action='store_false')\n",
    "    parser.add_argument('--dropout_p', type=float, default=0.1)\n",
    "    parser.add_argument('--dropout_w', type=float, default=0.000)\n",
    "    parser.add_argument('--bert_dropout_p', type=float, default=0.1)\n",
    "\n",
    "    # scheduler\n",
    "    parser.add_argument('--have_lr_scheduler', dest='have_lr_scheduler', action='store_false')\n",
    "    parser.add_argument('--multi_step_lr', type=str, default='10,20,30')\n",
    "    parser.add_argument('--lr_gamma', type=float, default=0.5)\n",
    "    parser.add_argument('--scheduler_type', type=str, default='ms', help='ms/rop/exp')\n",
    "    parser.add_argument('--output_dir', default='checkpoint')\n",
    "    parser.add_argument('--seed', type=int, default=2018,\n",
    "                        help='random seed for data shuffling, embedding init, etc.')\n",
    "    parser.add_argument('--grad_accumulation_step', type=int, default=1)\n",
    "\n",
    "    #fp 16\n",
    "    parser.add_argument('--fp16', action='store_true',\n",
    "                        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\")\n",
    "    parser.add_argument('--fp16_opt_level', type=str, default='O1',\n",
    "                        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
    "                             \"See details at https://nvidia.github.io/apex/amp.html\")\n",
    "\n",
    "    # adv training\n",
    "    parser.add_argument('--adv_train', action='store_true')\n",
    "\n",
    "    # the current release only includes smart perturbation\n",
    "    parser.add_argument('--adv_opt', default=0, type=int)\n",
    "    parser.add_argument('--adv_norm_level', default=0, type=int)\n",
    "    parser.add_argument('--adv_p_norm', default='inf', type=str)\n",
    "    parser.add_argument('--adv_alpha', default=1, type=float)\n",
    "    parser.add_argument('--adv_k', default=1, type=int)\n",
    "    parser.add_argument('--adv_step_size', default=1e-5, type=float)\n",
    "    parser.add_argument('--adv_noise_var', default=1e-5, type=float)\n",
    "    parser.add_argument('--adv_epsilon', default=1e-6, type=float)\n",
    "    parser.add_argument('--encode_mode', action='store_true', help=\"only encode test data\")\n",
    "    parser.add_argument('--debug', action='store_true', help=\"print debug info\")\n",
    "\n",
    "    # transformer cache\n",
    "    parser.add_argument(\"--transformer_cache\", default='.cache', type=str)\n",
    "    ############\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7a5efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n                              '--head_probe', '--head_probe_layer', '11', '--head_probe_idx', '0',\\n                              '--head_probe_n_classes', '13',\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse args\n",
    "parser = argparse.ArgumentParser()\n",
    "parser = data_config(parser)\n",
    "parser = model_config(parser)\n",
    "parser = train_config(parser)\n",
    "'''\n",
    "args = parser.parse_args(args=['--devices', '0',\n",
    "                              '--exp_name', 'bert-base-cased',\n",
    "                              '--dataset_name', 'COARSE/en',\n",
    "                              '--wandb',\n",
    "                               '--epochs', '5', '--batch_size', '16', #--learning_rate', '5e-3',\n",
    "                               '--bert_model_type', 'bert-base-cased', \n",
    "                               '--fp16',\n",
    "                              ])\n",
    "'''\n",
    "args = parser.parse_args(args=['--devices', '0',\n",
    "                              '--model_probe', '--model_probe_n_classes', '28',\n",
    "                              '--exp_name', 'bert-base-cased_GOEMOTIONS',\n",
    "                              '--dataset_name', 'GOEMOTIONS/en',\n",
    "                              '--wandb',\n",
    "                               '--epochs', '2', '--batch_size', '16', #'--learning_rate', '5e-3',\n",
    "                               '--bert_model_type', 'bert-base-cased', \n",
    "                               '--model_ckpt', 'checkpoint/bert-base-cased/model_0_0.pt',\n",
    "                               '--metric_of_choice', 'F1MAC',\n",
    "                               '--fp16',\n",
    "                              ])\n",
    "\n",
    "'''\n",
    "                              '--head_probe', '--head_probe_layer', '11', '--head_probe_idx', '0',\n",
    "                              '--head_probe_n_classes', '13',\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05bbef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some stuff in data can be automated\n",
    "dataset_name = args.dataset_name\n",
    "args.data_dir = f'experiments/{dataset_name}/{args.bert_model_type}'\n",
    "args.task_def = f'experiments/{dataset_name}/task_def.yaml'\n",
    "if \"/\" in dataset_name:\n",
    "    args.train_datasets = dataset_name.split(\"/\")[0].lower()\n",
    "else:\n",
    "    args.train_datasets = dataset_name.lower()\n",
    "\n",
    "# set task name, root data dir, and output dir.\n",
    "output_dir = args.output_dir\n",
    "data_dir = args.data_dir\n",
    "\n",
    "# multiple datasets are split by '_'\n",
    "args.train_datasets = args.train_datasets.split('_')\n",
    "\n",
    "# seed everything.\n",
    "set_environment(args.seed, args.cuda)\n",
    "\n",
    "# stores task: param_args for each TaskDef param\n",
    "task_defs = TaskDefs(args.task_def)\n",
    "encoder_type = args.encoder_type\n",
    "\n",
    "exp_name = args.exp_name\n",
    "\n",
    "# make log dir and set logger.\n",
    "log_path = f'logs/{exp_name}/{args.log_file}'\n",
    "Path(log_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "logger = create_logger(__name__, to_disk=True, log_file=log_path)\n",
    "\n",
    "# make output dir and set to absolute path.\n",
    "if not args.head_probe:\n",
    "    output_dir = Path(output_dir).joinpath(exp_name)\n",
    "\n",
    "output_dir = Path(os.path.abspath(output_dir))\n",
    "output_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e73f42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:00:08 Launching MT-DNN training.\n"
     ]
    }
   ],
   "source": [
    "print_message(logger, 'Launching MT-DNN training.')\n",
    "opt = vars(args)\n",
    "args.devices = [int(g) for g in args.devices]\n",
    "\n",
    "tasks = {}\n",
    "task_def_list = []\n",
    "train_data_lists = []\n",
    "train_datasets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41b6a386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:00:08 Loading experiments/GOEMOTIONS/en/bert-base-cased/goemotions_train.json as task 0\n",
      "Loaded 51103 samples out of 51103\n"
     ]
    }
   ],
   "source": [
    "# python prepro_std.py --model bert-base-multilingual-cased --dataset GOEMOTIONS/en --task_def experiments/GOEMOTIONS/en/task_def.yaml\n",
    "# create training dataset.\n",
    "for dataset in args.train_datasets:\n",
    "    prefix = dataset.split('_')[0]\n",
    "    if prefix not in tasks:\n",
    "        task_id = len(tasks)\n",
    "        tasks[prefix] = task_id\n",
    "\n",
    "        task_def = task_defs.get_task_def(prefix)\n",
    "        task_def_list.append(task_def)\n",
    "\n",
    "        train_path = os.path.join(data_dir, '{}_train.json'.format(dataset))\n",
    "        print_message(logger, 'Loading {} as task {}'.format(train_path, task_id))\n",
    "        \n",
    "        train_data_set = SingleTaskDataset(\n",
    "            path=train_path,\n",
    "            is_train=True,\n",
    "            maxlen=args.max_seq_len,\n",
    "            task_id=task_id,\n",
    "            task_def=task_def,\n",
    "            printable=True)\n",
    "\n",
    "        train_datasets.append(train_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb96df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_collater = Collater(\n",
    "    dropout_w=args.dropout_w,\n",
    "    encoder_type=encoder_type,\n",
    "    soft_label=False,\n",
    "    max_seq_len=args.max_seq_len,\n",
    "    do_padding=args.do_padding)\n",
    "\n",
    "multi_task_train_dataset = MultiTaskDataset(train_datasets)\n",
    "multi_task_batch_sampler = MultiTaskBatchSampler(\n",
    "                            train_datasets,\n",
    "                            args.batch_size,\n",
    "                            args.mix_opt,\n",
    "                            args.ratio,\n",
    "                            bin_on=args.bin_on,\n",
    "                            bin_size=args.bin_size,\n",
    "                            bin_grow_ratio=args.bin_grow_ratio)\n",
    "\n",
    "multi_task_train_dataloader = DataLoader(\n",
    "    multi_task_train_dataset,\n",
    "    batch_sampler=multi_task_batch_sampler,\n",
    "    collate_fn=train_collater.collate_fn,\n",
    "    pin_memory=len(args.devices)>0)\n",
    "\n",
    "train_data_lists.append(multi_task_train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "663563a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:00:10 ############# Gradient Accumulation Info #############\n",
      "04/29/2022 05:00:10 number of step: 6388\n",
      "04/29/2022 05:00:10 number of grad grad_accumulation step: 1\n",
      "04/29/2022 05:00:10 adjusted number of step: 6388\n",
      "04/29/2022 05:00:10 #######################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# div number of grad accumulation. \n",
    "n_batch_per_epoch = len(multi_task_train_dataloader) // args.grad_accumulation_step\n",
    "num_all_batches = args.epochs * n_batch_per_epoch\n",
    "print_message(logger, '############# Gradient Accumulation Info #############')\n",
    "print_message(logger, 'number of step: {}'.format(args.epochs * len(multi_task_train_dataloader)))\n",
    "print_message(logger, 'number of grad grad_accumulation step: {}'.format(args.grad_accumulation_step))\n",
    "print_message(logger, 'adjusted number of step: {}'.format(num_all_batches))\n",
    "print_message(logger, '#######################################\\n')\n",
    "\n",
    "if opt['encoder_type'] not in EncoderModelType._value2member_map_:\n",
    "    raise ValueError(\"encoder_type is out of pre-defined types\")\n",
    "\n",
    "literal_encoder_type = EncoderModelType(opt['encoder_type']).name.lower()\n",
    "config_class, _, _ = MODEL_CLASSES[literal_encoder_type]\n",
    "config = config_class.from_pretrained(args.bert_model_type).to_dict()\n",
    "\n",
    "config['attention_probs_dropout_prob'] = args.bert_dropout_p\n",
    "config['hidden_dropout_prob'] = args.bert_dropout_p\n",
    "config['multi_gpu_on'] = opt[\"multi_gpu_on\"]\n",
    "\n",
    "if args.num_hidden_layers > 0:\n",
    "    config['num_hidden_layers'] = args.num_hidden_layers\n",
    "\n",
    "opt['task_def_list'] = task_def_list\n",
    "opt['head_probe'] = args.head_probe\n",
    "opt.update(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cc47744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if resuming, load state dict, and get init epoch and step.\n",
    "if args.resume:\n",
    "    assert args.model_ckpt != '' and Path(args.model_ckpt).is_file(), args.model_ckpt\n",
    "    print_message(logger, f'loading model from {args.model_ckpt}')           \n",
    "    state_dict = torch.load(args.model_ckpt, map_location=f'cuda:{args.devices[0]}')\n",
    "\n",
    "    if args.jm_finetune:\n",
    "        if args.jm_finetune_new:\n",
    "            i = 0\n",
    "            while f'scoring_list.{i}.weight' in state_dict['state']:\n",
    "                del state_dict['state'][f'scoring_list.{i}.weight']\n",
    "                del state_dict['state'][f'scoring_list.{i}.bias']\n",
    "                i += 1\n",
    "        else:\n",
    "            i = 0\n",
    "            while f'scoring_list.{i}.weight' in state_dict['state']:\n",
    "                if i != args.jm_task_id:\n",
    "                    del state_dict['state'][f'scoring_list.{i}.weight']\n",
    "                    del state_dict['state'][f'scoring_list.{i}.bias']\n",
    "                i += 1\n",
    "\n",
    "            if args.jm_task_id != 0:\n",
    "                for param in ['weight', 'bias']:\n",
    "                    state_dict['state'][f'scoring_list.0.{param}'] = state_dict['state'][f'scoring_list.{args.jm_task_id}.{param}']\n",
    "                    del state_dict['state'][f'scoring_list.{args.jm_task_id}.{param}']\n",
    "\n",
    "    if not args.huggingface_ckpt:\n",
    "        split_model_name = args.model_ckpt.split(\"/\")[-1].split(\"_\")\n",
    "        if len(split_model_name) > 2:\n",
    "            init_epoch_idx = int(split_model_name[1]) + 1\n",
    "            init_global_step = int(split_model_name[2].split(\".\")[0]) + 1\n",
    "        else:\n",
    "            init_epoch_idx = int(split_model_name[1].split(\".\")[0]) + 1\n",
    "            init_global_step = 0\n",
    "    else:\n",
    "        init_epoch_idx = 0\n",
    "        init_global_step = 0\n",
    "\n",
    "else:\n",
    "    state_dict = None\n",
    "    init_epoch_idx = 0\n",
    "    init_global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3c33bf3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    }
   ],
   "source": [
    "model = MTDNNModel(\n",
    "        opt,\n",
    "        devices=args.devices,\n",
    "        num_train_step=num_all_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76602cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (args.head_probe or args.model_probe):\n",
    "    if state_dict is not None and args.resume:\n",
    "        if args.huggingface_ckpt:\n",
    "            if args.bert_model_type == 'bert-base-multilingual-cased':\n",
    "                params_to_remove = [\n",
    "                    \"cls.predictions.bias\",\n",
    "                    \"cls.predictions.transform.dense.weight\",\n",
    "                    \"cls.predictions.transform.dense.bias\",\n",
    "                    \"cls.predictions.transform.LayerNorm.weight\",\n",
    "                    \"cls.predictions.transform.LayerNorm.bias\",\n",
    "                    \"cls.predictions.decoder.weight\",\n",
    "                    \"cls.predictions.decoder.bias\"\n",
    "                ]\n",
    "            elif args.bert_model_type == 'xlm-roberta-base':\n",
    "                params_to_remove = []\n",
    "\n",
    "                # rename roberta -> bert\n",
    "                renamed_state_dict = {}\n",
    "                for n, p in state_dict.items():\n",
    "                    new_name = n.split('.')\n",
    "                    if new_name[0] == 'roberta':\n",
    "                        new_name[0] = 'bert'\n",
    "                        new_name = '.'.join(new_name)\n",
    "                        renamed_state_dict[new_name] = p\n",
    "                state_dict = renamed_state_dict\n",
    "\n",
    "            for param_name in params_to_remove:\n",
    "                if param_name in state_dict:\n",
    "                    print(f'{param_name} in state_dict, removing')\n",
    "                    del state_dict[param_name]\n",
    "                else:\n",
    "                    print(f'{param_name} not in state_dict')\n",
    "\n",
    "            _init_state_dict = model.network.state_dict()\n",
    "\n",
    "            params_to_add = [\n",
    "                    \"bert.pooler.dense.weight\",\n",
    "                    \"bert.pooler.dense.bias\",\n",
    "                    \"pooler.dense.weight\",\n",
    "                    \"pooler.dense.bias\"\n",
    "                ]\n",
    "            num_tasks = len(task_def_list)\n",
    "            for i in range(num_tasks):\n",
    "                params_to_add.extend([f\"scoring_list.{i}.weight\", f\"scoring_list.{i}.bias\"])\n",
    "\n",
    "            for param_name in params_to_add:\n",
    "                state_dict[param_name] = _init_state_dict[param_name]\n",
    "\n",
    "            state_dict = {'state': state_dict}\n",
    "\n",
    "        if args.jm_finetune and args.jm_finetune_new:\n",
    "            for param in ['weight', 'bias']:\n",
    "                state_dict['state'][f'scoring_list.0.{param}'] = model.network.state_dict()[f'scoring_list.0.{param}']\n",
    "\n",
    "        model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8350401",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.head_probe:\n",
    "    print_message(logger, f'attached head probe at layer #{args.head_probe_layer+1}, head #{args.head_probe_idx+1}')\n",
    "    opt['head_idx_to_probe'] = (args.head_probe_layer, args.head_probe_idx)\n",
    "\n",
    "    # freeze all params\n",
    "    for p in model.network.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # load model, making sure to match scoring_list params\n",
    "    if args.model_ckpt != '':\n",
    "        state_dict = torch.load(args.model_ckpt, map_location=f'cuda:{args.devices[0]}')\n",
    "        state_dict['state']['scoring_list.0.weight'] = model.network.state_dict()['scoring_list.0.weight']\n",
    "        state_dict['state']['scoring_list.0.bias'] = model.network.state_dict()['scoring_list.0.bias']\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "    # then attach probing head\n",
    "    model.attach_head_probe(\n",
    "        args.head_probe_layer,\n",
    "        args.head_probe_idx,\n",
    "        n_classes=args.head_probe_n_classes)\n",
    "    optimizer_parameters = model._get_param_groups()\n",
    "    model._setup_optim(optimizer_parameters, None, num_all_batches)\n",
    "\n",
    "    init_epoch_idx = 0\n",
    "    init_global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7f35d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:00:14 probing whole model. Setting n_epochs to 2.\n",
      "model_probe, loading model ckpt from checkpoint/bert-base-cased/model_0_0.pt\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "if args.model_probe:\n",
    "    print_message(logger, 'probing whole model. Setting n_epochs to 2.')\n",
    "    args.epochs = 2\n",
    "\n",
    "    # freeze all params\n",
    "    for p in model.network.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # load model, making sure to match scoring_list params\n",
    "    if args.model_ckpt != '':\n",
    "        print(f'model_probe, loading model ckpt from {args.model_ckpt}')\n",
    "        state_dict = torch.load(args.model_ckpt, map_location=f'cuda:{args.devices[0]}')\n",
    "        state_dict['state']['scoring_list.0.weight'] = model.network.state_dict()['scoring_list.0.weight']\n",
    "        state_dict['state']['scoring_list.0.bias'] = model.network.state_dict()['scoring_list.0.bias']\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "    # then attach probing head\n",
    "    model.attach_model_probe(n_classes=args.model_probe_n_classes)\n",
    "    optimizer_parameters = model._get_param_groups()\n",
    "    model._setup_optim(optimizer_parameters, None, num_all_batches)\n",
    "\n",
    "    init_epoch_idx = 0\n",
    "    init_global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "083541a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6380 samples out of 6380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maadilislam\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aadil/bert-probing/wandb/run-20220429_170014-2bo6a7i9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/aadilislam/soroush/runs/2bo6a7i9\" target=\"_blank\">bert-base-cased_GOEMOTIONS</a></strong> to <a href=\"https://wandb.ai/aadilislam/soroush\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_meta = task_defs._metric_meta_map[dataset]\n",
    "datasets = ['en']\n",
    "model_type = 'bert'\n",
    "device_id = args.devices[0]\n",
    "task = Experiment[dataset.upper()]\n",
    "task_def_path = args.task_def\n",
    "\n",
    "dev_data_lst = []\n",
    "for ds in datasets:\n",
    "    data_path = f'experiments/{task.name}/{ds}/{args.bert_model_type}/{task.name.lower()}_dev.json'\n",
    "    dev_data = build_dataset(\n",
    "        data_path,\n",
    "        task_def=TaskDefs(task_def_path).get_task_def(task.name.lower()),\n",
    "        device_id=device_id,\n",
    "        batch_size=8,\n",
    "        max_seq_len=512)\n",
    "    dev_data_lst.append(dev_data)  \n",
    "\n",
    "# dump config\n",
    "dump_opt(opt, output_dir)\n",
    "\n",
    "if args.gradient_probe:\n",
    "    save_path = Path('gradient_probe_outputs').joinpath(exp_name)\n",
    "    prediction_gradient(\n",
    "        args,\n",
    "        model, \n",
    "        multi_task_train_dataloader,\n",
    "        save_path\n",
    "    )\n",
    "    #return\n",
    "\n",
    "if args.wandb:\n",
    "    wandb.init(project='soroush', name=exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef7537c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:00:19 At epoch 0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:00:31 [e0] [1/3194] train loss: 3.35774 | dev score: 0.54274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/apex/amp/wrap.py:101: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629395347/work/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  return orig_fn(arg0, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "04/29/2022 05:00:45 [e0] [101/3194] train loss: 3.41249 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:00:59 [e0] [201/3194] train loss: 3.39703 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:01:13 [e0] [301/3194] train loss: 3.36840 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:01:28 [e0] [401/3194] train loss: 3.33131 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:01:42 [e0] [501/3194] train loss: 3.29059 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:01:56 [e0] [601/3194] train loss: 3.24417 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:02:10 [e0] [701/3194] train loss: 3.19909 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:02:24 [e0] [801/3194] train loss: 3.15737 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:02:38 [e0] [901/3194] train loss: 3.12231 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:02:51 [e0] [1001/3194] train loss: 3.09380 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:03:05 [e0] [1101/3194] train loss: 3.06784 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:03:18 [e0] [1201/3194] train loss: 3.04406 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:03:32 [e0] [1301/3194] train loss: 3.02120 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:03:46 [e0] [1401/3194] train loss: 3.00235 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:03:59 [e0] [1501/3194] train loss: 2.98649 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:04:13 [e0] [1601/3194] train loss: 2.97151 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:04:26 [e0] [1701/3194] train loss: 2.96179 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:04:40 [e0] [1801/3194] train loss: 2.95256 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:04:53 [e0] [1901/3194] train loss: 2.94059 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:05:07 [e0] [2001/3194] train loss: 2.93028 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:05:20 [e0] [2101/3194] train loss: 2.92379 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:05:34 [e0] [2201/3194] train loss: 2.91538 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:05:47 [e0] [2301/3194] train loss: 2.90727 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:06:01 [e0] [2401/3194] train loss: 2.90114 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:06:14 [e0] [2501/3194] train loss: 2.89500 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:06:28 [e0] [2601/3194] train loss: 2.88832 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:06:41 [e0] [2701/3194] train loss: 2.88355 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:06:55 [e0] [2801/3194] train loss: 2.87530 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:07:09 [e0] [2901/3194] train loss: 2.87037 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:07:22 [e0] [3001/3194] train loss: 2.86453 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:07:36 [e0] [3101/3194] train loss: 2.85764 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:07:38 Saving mt-dnn model to /home/aadil/bert-probing/checkpoint/bert-base-cased_GOEMOTIONS/model_0_3194.pt\n",
      "04/29/2022 05:07:38 At epoch 1\n",
      "04/29/2022 05:07:50 [e1] [7/3194] train loss: 2.85336 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:08:03 [e1] [107/3194] train loss: 2.84846 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:08:17 [e1] [207/3194] train loss: 2.84287 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:08:31 [e1] [307/3194] train loss: 2.83904 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:08:44 [e1] [407/3194] train loss: 2.83654 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:08:58 [e1] [507/3194] train loss: 2.83286 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:09:11 [e1] [607/3194] train loss: 2.82967 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:09:25 [e1] [707/3194] train loss: 2.82671 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:09:38 [e1] [807/3194] train loss: 2.82316 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:09:52 [e1] [907/3194] train loss: 2.82105 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "04/29/2022 05:10:05 [e1] [1007/3194] train loss: 2.81864 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:10:19 [e1] [1107/3194] train loss: 2.81610 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:10:32 [e1] [1207/3194] train loss: 2.81329 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:10:46 [e1] [1307/3194] train loss: 2.80992 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:10:59 [e1] [1407/3194] train loss: 2.80721 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:11:13 [e1] [1507/3194] train loss: 2.80465 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:11:26 [e1] [1607/3194] train loss: 2.80198 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:11:40 [e1] [1707/3194] train loss: 2.80089 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:11:54 [e1] [1807/3194] train loss: 2.79992 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:12:07 [e1] [1907/3194] train loss: 2.79716 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:12:21 [e1] [2007/3194] train loss: 2.79500 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:12:34 [e1] [2107/3194] train loss: 2.79394 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:12:48 [e1] [2207/3194] train loss: 2.79159 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:13:01 [e1] [2307/3194] train loss: 2.78992 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:13:15 [e1] [2407/3194] train loss: 2.78888 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:13:28 [e1] [2507/3194] train loss: 2.78724 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:13:42 [e1] [2607/3194] train loss: 2.78549 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:13:56 [e1] [2707/3194] train loss: 2.78423 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:14:09 [e1] [2807/3194] train loss: 2.78153 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:14:23 [e1] [2907/3194] train loss: 2.78032 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:14:36 [e1] [3007/3194] train loss: 2.77835 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "04/29/2022 05:14:50 [e1] [3107/3194] train loss: 2.77593 | dev score: 0.54274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 05:14:52 Saving mt-dnn model to /home/aadil/bert-probing/checkpoint/bert-base-cased_GOEMOTIONS/model_1_6388.pt\n"
     ]
    }
   ],
   "source": [
    "# main training loop\n",
    "for epoch in range(init_epoch_idx, init_epoch_idx+args.epochs):        \n",
    "    print_message(logger, f'At epoch {epoch}', level=1)\n",
    "    \n",
    "    for (batch_meta, batch_data) in multi_task_train_dataloader:\n",
    "        batch_meta, batch_data = Collater.patch_data(\n",
    "            torch.device(args.devices[0]),\n",
    "            batch_meta,\n",
    "            batch_data)\n",
    "\n",
    "        task_id = batch_meta['task_id']\n",
    "        model.update(batch_meta, batch_data)\n",
    "\n",
    "        metrics = []\n",
    "\n",
    "        if (model.updates - 1) % (args.log_per_updates) == 0:\n",
    "            # Based on evaluate_model_against_multiple_datasets\n",
    "            for dev_data in dev_data_lst:\n",
    "                metric = get_metric(model, dev_data, metric_meta, device_id, head_probe=False)[0]\n",
    "                metric = metric[args.metric_of_choice]\n",
    "                metrics.append(metric)\n",
    "\n",
    "            print_message(logger, f\"[e{epoch}] [{model.updates % n_batch_per_epoch}/{n_batch_per_epoch}] train loss: {model.train_loss.avg:.5f} | dev score: {metrics[0]:.5f}\")\n",
    "\n",
    "            if args.wandb:\n",
    "                wandb.log({\n",
    "                    'train/loss': model.train_loss.avg,\n",
    "                    'dev/score': metrics[0],\n",
    "                    'global_step': init_global_step + model.updates,\n",
    "                    'epoch': epoch\n",
    "                })\n",
    "\n",
    "    model_file = save_checkpoint(model, epoch, output_dir)\n",
    "    print_message(logger, f'Saving mt-dnn model to {model_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9a3655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_gpu_on and batch_size 8 -> 680 per epoch\n",
    "# multi_gpu_on and batch_size 6 (memory issues) -> 907 per epoch\n",
    "# single gpu and batch_size 8 -> 390 per epoch\n",
    "# *** single gpu and batch_size 16 -> 85 per epoch ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37947fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_model_probe_results import get_model_probe_scores\n",
    "from experiments.exp_def import (\n",
    "    Experiment,\n",
    "    LingualSetting,\n",
    "    TaskDefs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28720767",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = 0\n",
    "finetuned_task = Experiment.COARSE\n",
    "finetuned_setting = LingualSetting.BASE #?\n",
    "probe_setting = LingualSetting.BASE #?\n",
    "probe_task = Experiment.COARSE\n",
    "model_ckpt = 'checkpoint/COARSE/model_4_2500.pt'\n",
    "out_file_name = 'results.csv'\n",
    "metric = '' #?\n",
    "batch_size = 64\n",
    "max_seq_len = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ed16cc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_probe_outputs/PAWSX_multi\n",
      "data from experiments/PAWSX/multi/bert-base-multilingual-cased/pawsx_test.json\n",
      "Loaded 8000 samples out of 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PAWSX_multi -> PAWSX [multi], multi_head_training\n",
      "loading from checkpoint/my_pawsx_exp_1/model_1_6176.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                              | 0/125 [00:00<?, ?it/s]/home/aadil/anaconda3/envs/venv3.8/lib/python3.8/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "100%|████████████████████████████████████| 125/125 [00:24<00:00,  5.19it/s]\n"
     ]
    }
   ],
   "source": [
    "get_model_probe_scores(\n",
    "    finetuned_task,\n",
    "    finetuned_setting,\n",
    "    probe_setting,\n",
    "    probe_task,\n",
    "    model_ckpt,\n",
    "    out_file_name,\n",
    "    metric,\n",
    "    device_id,\n",
    "    'multi',\n",
    "    batch_size,\n",
    "    max_seq_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44b03c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e7d90f60a8b628b70394d2a2332723d4e001ac85fbb52530832d6774e8389f6"
  },
  "kernelspec": {
   "display_name": "Python [conda env:venv3.8] *",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
